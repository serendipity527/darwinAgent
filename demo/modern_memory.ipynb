#%%
#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
ç°ä»£ LangChain è®°å¿†å¯¹è¯ç³»ç»Ÿæ¼”ç¤º
ä½¿ç”¨ LangGraph å’Œæ–°çš„è®°å¿†ç®¡ç†æ–¹å¼

LangChain 0.3+ æ¨èä½¿ç”¨ LangGraph è¿›è¡Œè®°å¿†ç®¡ç†ï¼Œè€Œä¸æ˜¯ä¼ ç»Ÿçš„ Memory ç±»
"""

import os
import asyncio
from typing import Dict, List, Any, Optional, Annotated
from datetime import datetime

# å®‰è£…å¿…è¦çš„åŒ…
# uv pip install langgraph langchain-ollama

# LangGraph imports
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.checkpoint.memory import MemorySaver
from langgraph.prebuilt import create_react_agent

# LangChain imports
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_ollama import OllamaLLM
from langchain_openai import ChatOpenAI

print("ç°ä»£ LangChain è®°å¿†å¯¹è¯ç³»ç»Ÿæ¼”ç¤º (LangGraph)")
print("=" * 60)

#%%
# ===================== é…ç½®éƒ¨åˆ† =====================

# æ¨¡å‹é…ç½®
OLLAMA_BASE_URL = "http://localhost:11434"
OLLAMA_MODEL = "gemma:3b"

def create_llm(use_openai: bool = False):
    """åˆ›å»ºè¯­è¨€æ¨¡å‹å®ä¾‹"""
    if use_openai:
        return ChatOpenAI(
            model="gpt-3.5-turbo",
            temperature=0.7,
            max_tokens=1000
        )
    else:
        return OllamaLLM(
            base_url=OLLAMA_BASE_URL,
            model=OLLAMA_MODEL,
            temperature=0.7
        )

# åˆ›å»ºLLMå®ä¾‹
llm = create_llm(use_openai=False)

print(f"ä½¿ç”¨æ¨¡å‹: {OLLAMA_MODEL}")
print(f"Ollamaåœ°å€: {OLLAMA_BASE_URL}")

#%%
# ===================== 1. åŸºç¡€ LangGraph è®°å¿†æ¼”ç¤º =====================

print("\n1. åŸºç¡€ LangGraph è®°å¿†ç³»ç»Ÿ")
print("-" * 40)

# å®šä¹‰çŠ¶æ€
from typing_extensions import TypedDict

class State(TypedDict):
    messages: Annotated[List[BaseMessage], add_messages]

# åˆ›å»ºç®€å•çš„èŠå¤©æœºå™¨äºº
def chatbot_node(state: State):
    """èŠå¤©æœºå™¨äººèŠ‚ç‚¹"""
    # åˆ›å»ºç³»ç»Ÿæ¶ˆæ¯
    system_message = SystemMessage(content="""ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„AIåŠ©æ‰‹ã€‚
ä½ èƒ½è®°ä½å¯¹è¯å†å²ï¼Œå¹¶åŸºäºä¹‹å‰çš„å¯¹è¯å†…å®¹è¿›è¡Œå›å¤ã€‚
è¯·ä¿æŒå‹å¥½ã€æœ‰å¸®åŠ©çš„æ€åº¦ã€‚""")
    
    # å‡†å¤‡æ¶ˆæ¯åˆ—è¡¨
    messages = [system_message] + state["messages"]
    
    # è°ƒç”¨LLM
    response = llm.invoke(messages)
    
    # è¿”å›AIæ¶ˆæ¯
    return {"messages": [AIMessage(content=response)]}

# åˆ›å»ºå›¾
def create_basic_chat_graph():
    """åˆ›å»ºåŸºç¡€èŠå¤©å›¾"""
    graph = StateGraph(State)
    
    # æ·»åŠ èŠ‚ç‚¹
    graph.add_node("chatbot", chatbot_node)
    
    # æ·»åŠ è¾¹
    graph.add_edge(START, "chatbot")
    graph.add_edge("chatbot", END)
    
    # æ·»åŠ è®°å¿†æ£€æŸ¥ç‚¹
    memory = MemorySaver()
    
    # ç¼–è¯‘å›¾
    return graph.compile(checkpointer=memory)

# åˆ›å»ºèŠå¤©åº”ç”¨
basic_chat_app = create_basic_chat_graph()

print("LangGraph è®°å¿†ç‰¹ç‚¹:")
print("- è‡ªåŠ¨ç®¡ç†å¯¹è¯å†å²")
print("- æ”¯æŒå¤šç”¨æˆ·ã€å¤šä¼šè¯")
print("- å¯ä»¥ä¿å­˜å’Œæ¢å¤å¯¹è¯çŠ¶æ€")
print("- æ”¯æŒå¤æ‚çš„çŠ¶æ€ç®¡ç†")

def demo_basic_langgraph_memory():
    """æ¼”ç¤ºåŸºç¡€ LangGraph è®°å¿†"""
    print("\nå¼€å§‹ LangGraph è®°å¿†æ¼”ç¤º...")
    
    # é…ç½®ä¼šè¯
    config = {"configurable": {"thread_id": "demo_conversation_1"}}
    
    # æµ‹è¯•å¯¹è¯
    conversations = [
        "ä½ å¥½ï¼Œæˆ‘å«Aliceï¼Œæ˜¯ä¸€åæ•°æ®ç§‘å­¦å®¶",
        "æˆ‘åœ¨ç ”ç©¶æœºå™¨å­¦ä¹ ç®—æ³•",
        "ä½ è¿˜è®°å¾—æˆ‘çš„åå­—å—ï¼Ÿ",
        "æˆ‘çš„èŒä¸šæ˜¯ä»€ä¹ˆï¼Ÿ"
    ]
    
    for i, user_input in enumerate(conversations, 1):
        # è°ƒç”¨èŠå¤©åº”ç”¨
        result = basic_chat_app.invoke(
            {"messages": [HumanMessage(content=user_input)]},
            config=config
        )
        
        print(f"\nç¬¬{i}è½®å¯¹è¯:")
        print(f"ç”¨æˆ·: {user_input}")
        print(f"AI: {result['messages'][-1].content}")
    
    # æ˜¾ç¤ºå®Œæ•´çš„å¯¹è¯å†å²
    print(f"\nå®Œæ•´å¯¹è¯å†å²:")
    state = basic_chat_app.get_state(config)
    for msg in state.values["messages"]:
        role = "ç”¨æˆ·" if isinstance(msg, HumanMessage) else "AI"
        print(f"{role}: {msg.content}")

# è¿è¡Œæ¼”ç¤º
demo_basic_langgraph_memory()

#%%
# ===================== 2. å¸¦æœ‰è®°å¿†ç®¡ç†çš„é«˜çº§èŠå¤©ç³»ç»Ÿ =====================

print("\n\n2. é«˜çº§è®°å¿†ç®¡ç† - æ¶ˆæ¯ä¿®å‰ªå’Œæ‘˜è¦")
print("-" * 50)

from langchain_core.messages import trim_messages

class AdvancedState(TypedDict):
    messages: Annotated[List[BaseMessage], add_messages]
    summary: str  # å¯¹è¯æ‘˜è¦

def summarize_conversation(messages: List[BaseMessage]) -> str:
    """æ€»ç»“å¯¹è¯å†å²"""
    if len(messages) < 4:  # å°‘äº2è½®å¯¹è¯ä¸éœ€è¦æ‘˜è¦
        return ""
    
    # åˆ›å»ºæ‘˜è¦æç¤º
    summary_prompt = f"""è¯·ç®€æ´åœ°æ€»ç»“ä»¥ä¸‹å¯¹è¯çš„è¦ç‚¹ï¼š

{chr(10).join([f"{type(msg).__name__}: {msg.content}" for msg in messages[:-2]])}

æ‘˜è¦:"""
    
    try:
        summary = llm.invoke(summary_prompt)
        return summary
    except:
        return "å¯¹è¯æ‘˜è¦ç”Ÿæˆå¤±è´¥"

def advanced_chatbot_node(state: AdvancedState):
    """é«˜çº§èŠå¤©æœºå™¨äººèŠ‚ç‚¹ï¼Œæ”¯æŒæ¶ˆæ¯ä¿®å‰ªå’Œæ‘˜è¦"""
    messages = state["messages"]
    summary = state.get("summary", "")
    
    # å¦‚æœæ¶ˆæ¯å¤ªå¤šï¼Œè¿›è¡Œä¿®å‰ª
    if len(messages) > 10:  # ä¿ç•™æœ€è¿‘5è½®å¯¹è¯
        # ç”Ÿæˆæ‘˜è¦
        if not summary:
            summary = summarize_conversation(messages[:-6])
        
        # ä¿®å‰ªæ¶ˆæ¯ï¼Œåªä¿ç•™æœ€è¿‘çš„æ¶ˆæ¯
        trimmed_messages = messages[-6:]
        
        # åˆ›å»ºåŒ…å«æ‘˜è¦çš„ç³»ç»Ÿæ¶ˆæ¯
        system_content = f"""ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„AIåŠ©æ‰‹ã€‚

å¯¹è¯æ‘˜è¦: {summary}

è¯·åŸºäºå¯¹è¯æ‘˜è¦å’Œæœ€è¿‘çš„å¯¹è¯å†å²è¿›è¡Œå›å¤ã€‚"""
        
        system_message = SystemMessage(content=system_content)
        final_messages = [system_message] + trimmed_messages
        
        return {
            "messages": [AIMessage(content=llm.invoke(final_messages))],
            "summary": summary
        }
    else:
        # æ­£å¸¸å¤„ç†
        system_message = SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„AIåŠ©æ‰‹ï¼Œèƒ½è®°ä½å¯¹è¯å†å²ã€‚")
        final_messages = [system_message] + messages
        
        return {
            "messages": [AIMessage(content=llm.invoke(final_messages))],
            "summary": summary
        }

def create_advanced_chat_graph():
    """åˆ›å»ºé«˜çº§èŠå¤©å›¾"""
    graph = StateGraph(AdvancedState)
    
    # æ·»åŠ èŠ‚ç‚¹
    graph.add_node("chatbot", advanced_chatbot_node)
    
    # æ·»åŠ è¾¹
    graph.add_edge(START, "chatbot")
    graph.add_edge("chatbot", END)
    
    # æ·»åŠ è®°å¿†æ£€æŸ¥ç‚¹
    memory = MemorySaver()
    
    # ç¼–è¯‘å›¾
    return graph.compile(checkpointer=memory)

# åˆ›å»ºé«˜çº§èŠå¤©åº”ç”¨
advanced_chat_app = create_advanced_chat_graph()

def demo_advanced_memory():
    """æ¼”ç¤ºé«˜çº§è®°å¿†ç®¡ç†"""
    print("\nå¼€å§‹é«˜çº§è®°å¿†ç®¡ç†æ¼”ç¤º...")
    
    config = {"configurable": {"thread_id": "advanced_demo"}}
    
    # æ¨¡æ‹Ÿé•¿å¯¹è¯
    conversations = [
        "ä½ å¥½ï¼Œæˆ‘å«Bobï¼Œæ˜¯ä¸€åè½¯ä»¶å·¥ç¨‹å¸ˆ",
        "æˆ‘åœ¨ä¸€å®¶ç§‘æŠ€å…¬å¸å·¥ä½œï¼Œä¸»è¦åšåç«¯å¼€å‘",
        "æˆ‘å–œæ¬¢Pythonå’ŒGoè¯­è¨€",
        "æœ€è¿‘åœ¨å­¦ä¹ Kuberneteså’ŒDocker",
        "æˆ‘çš„å›¢é˜Ÿæœ‰8ä¸ªäºº",
        "æˆ‘ä»¬æ­£åœ¨å¼€å‘ä¸€ä¸ªå¾®æœåŠ¡æ¶æ„çš„é¡¹ç›®",
        "è¿™ä¸ªé¡¹ç›®é¢„è®¡éœ€è¦6ä¸ªæœˆå®Œæˆ",
        "æˆ‘ä»¬ä½¿ç”¨æ•æ·å¼€å‘æ–¹æ³•",
        "æ¯ä¸¤å‘¨ä¸€ä¸ªè¿­ä»£",
        "æˆ‘è´Ÿè´£ç”¨æˆ·è®¤è¯æ¨¡å—",
        "è¿˜æœ‰APIç½‘å…³çš„è®¾è®¡",
        "ä½ è¿˜è®°å¾—æˆ‘çš„åå­—å—ï¼Ÿ",  # æµ‹è¯•é•¿æœŸè®°å¿†
        "æˆ‘åœ¨åšä»€ä¹ˆé¡¹ç›®ï¼Ÿ",
        "æˆ‘è´Ÿè´£å“ªäº›æ¨¡å—ï¼Ÿ"
    ]
    
    for i, user_input in enumerate(conversations, 1):
        result = advanced_chat_app.invoke(
            {"messages": [HumanMessage(content=user_input)]},
            config=config
        )
        
        print(f"\nç¬¬{i}è½®å¯¹è¯:")
        print(f"ç”¨æˆ·: {user_input}")
        print(f"AI: {result['messages'][-1].content}")
        
        # æ˜¾ç¤ºçŠ¶æ€ä¿¡æ¯
        state = advanced_chat_app.get_state(config)
        print(f"å½“å‰æ¶ˆæ¯æ•°: {len(state.values['messages'])}")
        if state.values.get('summary'):
            print(f"å¯¹è¯æ‘˜è¦: {state.values['summary'][:100]}...")

# è¿è¡Œæ¼”ç¤º
demo_advanced_memory()

#%%
# ===================== 3. å¤šç”¨æˆ·ä¼šè¯ç®¡ç† =====================

print("\n\n3. å¤šç”¨æˆ·ä¼šè¯ç®¡ç†")
print("-" * 30)

def demo_multi_user_sessions():
    """æ¼”ç¤ºå¤šç”¨æˆ·ä¼šè¯ç®¡ç†"""
    print("\nå¤šç”¨æˆ·ä¼šè¯æ¼”ç¤º...")
    
    # ç”¨æˆ·1çš„ä¼šè¯
    user1_config = {"configurable": {"thread_id": "user_alice"}}
    user2_config = {"configurable": {"thread_id": "user_bob"}}
    
    # ç”¨æˆ·1çš„å¯¹è¯
    print("\n=== ç”¨æˆ·Aliceçš„ä¼šè¯ ===")
    result1 = basic_chat_app.invoke(
        {"messages": [HumanMessage(content="ä½ å¥½ï¼Œæˆ‘æ˜¯Aliceï¼Œæˆ‘å–œæ¬¢ç”»ç”»")]},
        config=user1_config
    )
    print(f"Alice: ä½ å¥½ï¼Œæˆ‘æ˜¯Aliceï¼Œæˆ‘å–œæ¬¢ç”»ç”»")
    print(f"AI: {result1['messages'][-1].content}")
    
    # ç”¨æˆ·2çš„å¯¹è¯
    print("\n=== ç”¨æˆ·Bobçš„ä¼šè¯ ===")
    result2 = basic_chat_app.invoke(
        {"messages": [HumanMessage(content="å—¨ï¼Œæˆ‘æ˜¯Bobï¼Œæˆ‘æ˜¯ç¨‹åºå‘˜")]},
        config=user2_config
    )
    print(f"Bob: å—¨ï¼Œæˆ‘æ˜¯Bobï¼Œæˆ‘æ˜¯ç¨‹åºå‘˜")
    print(f"AI: {result2['messages'][-1].content}")
    
    # ç»§ç»­ç”¨æˆ·1çš„å¯¹è¯
    print("\n=== ç»§ç»­Aliceçš„ä¼šè¯ ===")
    result3 = basic_chat_app.invoke(
        {"messages": [HumanMessage(content="ä½ è¿˜è®°å¾—æˆ‘çš„çˆ±å¥½å—ï¼Ÿ")]},
        config=user1_config
    )
    print(f"Alice: ä½ è¿˜è®°å¾—æˆ‘çš„çˆ±å¥½å—ï¼Ÿ")
    print(f"AI: {result3['messages'][-1].content}")
    
    # ç»§ç»­ç”¨æˆ·2çš„å¯¹è¯
    print("\n=== ç»§ç»­Bobçš„ä¼šè¯ ===")
    result4 = basic_chat_app.invoke(
        {"messages": [HumanMessage(content="æˆ‘çš„èŒä¸šæ˜¯ä»€ä¹ˆï¼Ÿ")]},
        config=user2_config
    )
    print(f"Bob: æˆ‘çš„èŒä¸šæ˜¯ä»€ä¹ˆï¼Ÿ")
    print(f"AI: {result4['messages'][-1].content}")

# è¿è¡Œå¤šç”¨æˆ·æ¼”ç¤º
demo_multi_user_sessions()

#%%
# ===================== 4. ä¸ä¼ ç»ŸMemoryçš„å¯¹æ¯” =====================

print("\n\n4. ä¼ ç»ŸMemory vs LangGraphè®°å¿†å¯¹æ¯”")
print("-" * 45)

comparison_table = """
ç‰¹æ€§å¯¹æ¯”:

| ç‰¹æ€§ | ä¼ ç»ŸMemoryç±» | LangGraphè®°å¿† |
|------|-------------|---------------|
| å¤šç”¨æˆ·æ”¯æŒ | âŒ éœ€è¦æ‰‹åŠ¨å®ç° | âœ… å†…ç½®æ”¯æŒ |
| å¤šä¼šè¯ç®¡ç† | âŒ å¤æ‚ | âœ… ç®€å•é…ç½® |
| çŠ¶æ€æŒä¹…åŒ– | âŒ æœ‰é™ | âœ… å®Œæ•´æ”¯æŒ |
| é”™è¯¯æ¢å¤ | âŒ å›°éš¾ | âœ… å†…ç½®æ”¯æŒ |
| å¤æ‚çŠ¶æ€ç®¡ç† | âŒ ä¸æ”¯æŒ | âœ… å®Œå…¨æ”¯æŒ |
| å·¥å…·è°ƒç”¨å…¼å®¹ | âŒ æœ‰é—®é¢˜ | âœ… å®Œç¾å…¼å®¹ |
| è‡ªå®šä¹‰é€»è¾‘ | âŒ å—é™ | âœ… é«˜åº¦çµæ´» |
| ç»´æŠ¤çŠ¶æ€ | âš ï¸ å³å°†å¼ƒç”¨ | âœ… æ¨èä½¿ç”¨ |

æ¨èä½¿ç”¨åœºæ™¯:
- æ–°é¡¹ç›®: ç›´æ¥ä½¿ç”¨ LangGraph
- ç®€å•èŠå¤©: å¯ä»¥ç»§ç»­ä½¿ç”¨ RunnableWithMessageHistory
- å¤æ‚åº”ç”¨: å¼ºçƒˆæ¨è LangGraph
- ç”Ÿäº§ç¯å¢ƒ: LangGraph æä¾›æ›´å¥½çš„å¯é æ€§
"""

print(comparison_table)

#%%
# ===================== æ€»ç»“ =====================

print("\n" + "="*60)
print("ç°ä»£ LangChain è®°å¿†ç³»ç»Ÿæ€»ç»“")
print("="*60)

summary_text = """
LangGraph è®°å¿†ç³»ç»Ÿçš„ä¼˜åŠ¿:

1. ğŸ—ï¸ æ¶æ„ä¼˜åŠ¿
   - åŸºäºå›¾çš„çŠ¶æ€ç®¡ç†
   - å†…ç½®æ£€æŸ¥ç‚¹æœºåˆ¶
   - æ”¯æŒå¤æ‚çš„å·¥ä½œæµ

2. ğŸ‘¥ å¤šç”¨æˆ·æ”¯æŒ
   - å¤©ç„¶æ”¯æŒå¤šç”¨æˆ·ã€å¤šä¼šè¯
   - çº¿ç¨‹å®‰å…¨çš„çŠ¶æ€ç®¡ç†
   - ç‹¬ç«‹çš„ä¼šè¯éš”ç¦»

3. ğŸ”„ çŠ¶æ€æŒä¹…åŒ–
   - å®Œæ•´çš„çŠ¶æ€ä¿å­˜å’Œæ¢å¤
   - æ”¯æŒå¤šç§å­˜å‚¨åç«¯
   - é”™è¯¯æ¢å¤èƒ½åŠ›

4. ğŸ› ï¸ å¼€å‘ä½“éªŒ
   - æ›´ç›´è§‚çš„APIè®¾è®¡
   - æ›´å¥½çš„è°ƒè¯•æ”¯æŒ
   - é«˜åº¦å¯å®šåˆ¶

5. ğŸš€ æ€§èƒ½å’Œå¯é æ€§
   - æ›´å¥½çš„å†…å­˜ç®¡ç†
   - æ”¯æŒå¼‚æ­¥æ“ä½œ
   - ç”Ÿäº§ç¯å¢ƒå°±ç»ª

è¿ç§»å»ºè®®:
- æ–°é¡¹ç›®: ç›´æ¥ä½¿ç”¨ LangGraph
- ç°æœ‰é¡¹ç›®: é€æ­¥è¿ç§»åˆ° LangGraph
- ç®€å•åº”ç”¨: å¯ä»¥ç»§ç»­ä½¿ç”¨ç°æœ‰çš„ Memory ç±»

LangGraph ä»£è¡¨äº† LangChain è®°å¿†ç³»ç»Ÿçš„æœªæ¥æ–¹å‘ï¼
"""

print(summary_text)

print("\næ¼”ç¤ºå®Œæˆï¼")
print("å»ºè®®åœ¨å®é™…é¡¹ç›®ä¸­ä½¿ç”¨ LangGraph æ¥ç®¡ç†å¯¹è¯è®°å¿†ã€‚")
