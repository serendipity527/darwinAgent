#%%
#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
现代 LangChain 记忆对话系统演示
使用 LangGraph 和新的记忆管理方式

LangChain 0.3+ 推荐使用 LangGraph 进行记忆管理，而不是传统的 Memory 类
"""

import os
import asyncio
from typing import Dict, List, Any, Optional, Annotated
from datetime import datetime

# 安装必要的包
# uv pip install langgraph langchain-ollama

# LangGraph imports
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.checkpoint.memory import MemorySaver
from langgraph.prebuilt import create_react_agent

# LangChain imports
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_ollama import OllamaLLM
from langchain_openai import ChatOpenAI

print("现代 LangChain 记忆对话系统演示 (LangGraph)")
print("=" * 60)

#%%
# ===================== 配置部分 =====================

# 模型配置
OLLAMA_BASE_URL = "http://localhost:11434"
OLLAMA_MODEL = "gemma:3b"

def create_llm(use_openai: bool = False):
    """创建语言模型实例"""
    if use_openai:
        return ChatOpenAI(
            model="gpt-3.5-turbo",
            temperature=0.7,
            max_tokens=1000
        )
    else:
        return OllamaLLM(
            base_url=OLLAMA_BASE_URL,
            model=OLLAMA_MODEL,
            temperature=0.7
        )

# 创建LLM实例
llm = create_llm(use_openai=False)

print(f"使用模型: {OLLAMA_MODEL}")
print(f"Ollama地址: {OLLAMA_BASE_URL}")

#%%
# ===================== 1. 基础 LangGraph 记忆演示 =====================

print("\n1. 基础 LangGraph 记忆系统")
print("-" * 40)

# 定义状态
from typing_extensions import TypedDict

class State(TypedDict):
    messages: Annotated[List[BaseMessage], add_messages]

# 创建简单的聊天机器人
def chatbot_node(state: State):
    """聊天机器人节点"""
    # 创建系统消息
    system_message = SystemMessage(content="""你是一个友好的AI助手。
你能记住对话历史，并基于之前的对话内容进行回复。
请保持友好、有帮助的态度。""")
    
    # 准备消息列表
    messages = [system_message] + state["messages"]
    
    # 调用LLM
    response = llm.invoke(messages)
    
    # 返回AI消息
    return {"messages": [AIMessage(content=response)]}

# 创建图
def create_basic_chat_graph():
    """创建基础聊天图"""
    graph = StateGraph(State)
    
    # 添加节点
    graph.add_node("chatbot", chatbot_node)
    
    # 添加边
    graph.add_edge(START, "chatbot")
    graph.add_edge("chatbot", END)
    
    # 添加记忆检查点
    memory = MemorySaver()
    
    # 编译图
    return graph.compile(checkpointer=memory)

# 创建聊天应用
basic_chat_app = create_basic_chat_graph()

print("LangGraph 记忆特点:")
print("- 自动管理对话历史")
print("- 支持多用户、多会话")
print("- 可以保存和恢复对话状态")
print("- 支持复杂的状态管理")

def demo_basic_langgraph_memory():
    """演示基础 LangGraph 记忆"""
    print("\n开始 LangGraph 记忆演示...")
    
    # 配置会话
    config = {"configurable": {"thread_id": "demo_conversation_1"}}
    
    # 测试对话
    conversations = [
        "你好，我叫Alice，是一名数据科学家",
        "我在研究机器学习算法",
        "你还记得我的名字吗？",
        "我的职业是什么？"
    ]
    
    for i, user_input in enumerate(conversations, 1):
        # 调用聊天应用
        result = basic_chat_app.invoke(
            {"messages": [HumanMessage(content=user_input)]},
            config=config
        )
        
        print(f"\n第{i}轮对话:")
        print(f"用户: {user_input}")
        print(f"AI: {result['messages'][-1].content}")
    
    # 显示完整的对话历史
    print(f"\n完整对话历史:")
    state = basic_chat_app.get_state(config)
    for msg in state.values["messages"]:
        role = "用户" if isinstance(msg, HumanMessage) else "AI"
        print(f"{role}: {msg.content}")

# 运行演示
demo_basic_langgraph_memory()

#%%
# ===================== 2. 带有记忆管理的高级聊天系统 =====================

print("\n\n2. 高级记忆管理 - 消息修剪和摘要")
print("-" * 50)

from langchain_core.messages import trim_messages

class AdvancedState(TypedDict):
    messages: Annotated[List[BaseMessage], add_messages]
    summary: str  # 对话摘要

def summarize_conversation(messages: List[BaseMessage]) -> str:
    """总结对话历史"""
    if len(messages) < 4:  # 少于2轮对话不需要摘要
        return ""
    
    # 创建摘要提示
    summary_prompt = f"""请简洁地总结以下对话的要点：

{chr(10).join([f"{type(msg).__name__}: {msg.content}" for msg in messages[:-2]])}

摘要:"""
    
    try:
        summary = llm.invoke(summary_prompt)
        return summary
    except:
        return "对话摘要生成失败"

def advanced_chatbot_node(state: AdvancedState):
    """高级聊天机器人节点，支持消息修剪和摘要"""
    messages = state["messages"]
    summary = state.get("summary", "")
    
    # 如果消息太多，进行修剪
    if len(messages) > 10:  # 保留最近5轮对话
        # 生成摘要
        if not summary:
            summary = summarize_conversation(messages[:-6])
        
        # 修剪消息，只保留最近的消息
        trimmed_messages = messages[-6:]
        
        # 创建包含摘要的系统消息
        system_content = f"""你是一个友好的AI助手。

对话摘要: {summary}

请基于对话摘要和最近的对话历史进行回复。"""
        
        system_message = SystemMessage(content=system_content)
        final_messages = [system_message] + trimmed_messages
        
        return {
            "messages": [AIMessage(content=llm.invoke(final_messages))],
            "summary": summary
        }
    else:
        # 正常处理
        system_message = SystemMessage(content="你是一个友好的AI助手，能记住对话历史。")
        final_messages = [system_message] + messages
        
        return {
            "messages": [AIMessage(content=llm.invoke(final_messages))],
            "summary": summary
        }

def create_advanced_chat_graph():
    """创建高级聊天图"""
    graph = StateGraph(AdvancedState)
    
    # 添加节点
    graph.add_node("chatbot", advanced_chatbot_node)
    
    # 添加边
    graph.add_edge(START, "chatbot")
    graph.add_edge("chatbot", END)
    
    # 添加记忆检查点
    memory = MemorySaver()
    
    # 编译图
    return graph.compile(checkpointer=memory)

# 创建高级聊天应用
advanced_chat_app = create_advanced_chat_graph()

def demo_advanced_memory():
    """演示高级记忆管理"""
    print("\n开始高级记忆管理演示...")
    
    config = {"configurable": {"thread_id": "advanced_demo"}}
    
    # 模拟长对话
    conversations = [
        "你好，我叫Bob，是一名软件工程师",
        "我在一家科技公司工作，主要做后端开发",
        "我喜欢Python和Go语言",
        "最近在学习Kubernetes和Docker",
        "我的团队有8个人",
        "我们正在开发一个微服务架构的项目",
        "这个项目预计需要6个月完成",
        "我们使用敏捷开发方法",
        "每两周一个迭代",
        "我负责用户认证模块",
        "还有API网关的设计",
        "你还记得我的名字吗？",  # 测试长期记忆
        "我在做什么项目？",
        "我负责哪些模块？"
    ]
    
    for i, user_input in enumerate(conversations, 1):
        result = advanced_chat_app.invoke(
            {"messages": [HumanMessage(content=user_input)]},
            config=config
        )
        
        print(f"\n第{i}轮对话:")
        print(f"用户: {user_input}")
        print(f"AI: {result['messages'][-1].content}")
        
        # 显示状态信息
        state = advanced_chat_app.get_state(config)
        print(f"当前消息数: {len(state.values['messages'])}")
        if state.values.get('summary'):
            print(f"对话摘要: {state.values['summary'][:100]}...")

# 运行演示
demo_advanced_memory()

#%%
# ===================== 3. 多用户会话管理 =====================

print("\n\n3. 多用户会话管理")
print("-" * 30)

def demo_multi_user_sessions():
    """演示多用户会话管理"""
    print("\n多用户会话演示...")
    
    # 用户1的会话
    user1_config = {"configurable": {"thread_id": "user_alice"}}
    user2_config = {"configurable": {"thread_id": "user_bob"}}
    
    # 用户1的对话
    print("\n=== 用户Alice的会话 ===")
    result1 = basic_chat_app.invoke(
        {"messages": [HumanMessage(content="你好，我是Alice，我喜欢画画")]},
        config=user1_config
    )
    print(f"Alice: 你好，我是Alice，我喜欢画画")
    print(f"AI: {result1['messages'][-1].content}")
    
    # 用户2的对话
    print("\n=== 用户Bob的会话 ===")
    result2 = basic_chat_app.invoke(
        {"messages": [HumanMessage(content="嗨，我是Bob，我是程序员")]},
        config=user2_config
    )
    print(f"Bob: 嗨，我是Bob，我是程序员")
    print(f"AI: {result2['messages'][-1].content}")
    
    # 继续用户1的对话
    print("\n=== 继续Alice的会话 ===")
    result3 = basic_chat_app.invoke(
        {"messages": [HumanMessage(content="你还记得我的爱好吗？")]},
        config=user1_config
    )
    print(f"Alice: 你还记得我的爱好吗？")
    print(f"AI: {result3['messages'][-1].content}")
    
    # 继续用户2的对话
    print("\n=== 继续Bob的会话 ===")
    result4 = basic_chat_app.invoke(
        {"messages": [HumanMessage(content="我的职业是什么？")]},
        config=user2_config
    )
    print(f"Bob: 我的职业是什么？")
    print(f"AI: {result4['messages'][-1].content}")

# 运行多用户演示
demo_multi_user_sessions()

#%%
# ===================== 4. 与传统Memory的对比 =====================

print("\n\n4. 传统Memory vs LangGraph记忆对比")
print("-" * 45)

comparison_table = """
特性对比:

| 特性 | 传统Memory类 | LangGraph记忆 |
|------|-------------|---------------|
| 多用户支持 | ❌ 需要手动实现 | ✅ 内置支持 |
| 多会话管理 | ❌ 复杂 | ✅ 简单配置 |
| 状态持久化 | ❌ 有限 | ✅ 完整支持 |
| 错误恢复 | ❌ 困难 | ✅ 内置支持 |
| 复杂状态管理 | ❌ 不支持 | ✅ 完全支持 |
| 工具调用兼容 | ❌ 有问题 | ✅ 完美兼容 |
| 自定义逻辑 | ❌ 受限 | ✅ 高度灵活 |
| 维护状态 | ⚠️ 即将弃用 | ✅ 推荐使用 |

推荐使用场景:
- 新项目: 直接使用 LangGraph
- 简单聊天: 可以继续使用 RunnableWithMessageHistory
- 复杂应用: 强烈推荐 LangGraph
- 生产环境: LangGraph 提供更好的可靠性
"""

print(comparison_table)

#%%
# ===================== 总结 =====================

print("\n" + "="*60)
print("现代 LangChain 记忆系统总结")
print("="*60)

summary_text = """
LangGraph 记忆系统的优势:

1. 🏗️ 架构优势
   - 基于图的状态管理
   - 内置检查点机制
   - 支持复杂的工作流

2. 👥 多用户支持
   - 天然支持多用户、多会话
   - 线程安全的状态管理
   - 独立的会话隔离

3. 🔄 状态持久化
   - 完整的状态保存和恢复
   - 支持多种存储后端
   - 错误恢复能力

4. 🛠️ 开发体验
   - 更直观的API设计
   - 更好的调试支持
   - 高度可定制

5. 🚀 性能和可靠性
   - 更好的内存管理
   - 支持异步操作
   - 生产环境就绪

迁移建议:
- 新项目: 直接使用 LangGraph
- 现有项目: 逐步迁移到 LangGraph
- 简单应用: 可以继续使用现有的 Memory 类

LangGraph 代表了 LangChain 记忆系统的未来方向！
"""

print(summary_text)

print("\n演示完成！")
print("建议在实际项目中使用 LangGraph 来管理对话记忆。")
