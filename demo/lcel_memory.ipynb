{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T12:32:29.462007Z",
     "start_time": "2025-07-21T12:32:28.773565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "使用 LCEL (LangChain Expression Language) 实现对话记忆\n",
    "展示多种在 LCEL 中管理对话历史的方法\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from typing import Dict, List, Any, Optional\n",
    "from datetime import datetime\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory, InMemoryChatMessageHistory\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "print(\"LCEL 对话记忆实现演示\")\n",
    "print(\"=\" * 40)\n"
   ],
   "id": "962b4a5c29d56c13",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LCEL 对话记忆实现演示\n",
      "========================================\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T12:54:48.135978Z",
     "start_time": "2025-07-21T12:54:48.085913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===================== 配置部分 =====================\n",
    "\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434\"\n",
    "OLLAMA_MODEL = \"gemma3:4b\"\n",
    "\n",
    "def create_llm():\n",
    "    \"\"\"创建LLM实例\"\"\"\n",
    "    return OllamaLLM(\n",
    "        base_url=OLLAMA_BASE_URL,\n",
    "        model=OLLAMA_MODEL,\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "llm = create_llm()\n",
    "print(f\"使用模型: {OLLAMA_MODEL}\")\n"
   ],
   "id": "59a2f706d46042fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用模型: gemma3:4b\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ===================== 方法1: 手动管理对话历史 =====================\n",
    "\n",
    "print(\"\\n1. 手动管理对话历史\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "class ManualMemoryChain:\n",
    "    \"\"\"手动管理对话历史的链\"\"\"\n",
    "    \n",
    "    def __init__(self, llm):\n",
    "        self.llm = llm\n",
    "        self.history: List[BaseMessage] = []\n",
    "        \n",
    "        # 创建提示模板\n",
    "        self.prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"你是一个友好的AI助手，能够记住对话历史。\"),\n",
    "            MessagesPlaceholder(variable_name=\"history\"),\n",
    "            (\"human\", \"{input}\")\n",
    "        ])\n",
    "        \n",
    "        # 创建链\n",
    "        self.chain = self.prompt | self.llm | StrOutputParser()\n",
    "    \n",
    "    def invoke(self, user_input: str) -> str:\n",
    "        \"\"\"调用链并更新历史\"\"\"\n",
    "        # 调用链\n",
    "        response = self.chain.invoke({\n",
    "            \"history\": self.history,\n",
    "            \"input\": user_input\n",
    "        })\n",
    "        \n",
    "        # 更新历史\n",
    "        self.history.append(HumanMessage(content=user_input))\n",
    "        self.history.append(AIMessage(content=response))\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def clear_history(self):\n",
    "        \"\"\"清空历史\"\"\"\n",
    "        self.history = []\n",
    "    \n",
    "    def get_history(self) -> List[BaseMessage]:\n",
    "        \"\"\"获取历史\"\"\"\n",
    "        return self.history.copy()\n",
    "\n",
    "# 演示手动记忆管理\n",
    "def demo_manual_memory():\n",
    "    \"\"\"演示手动记忆管理\"\"\"\n",
    "    print(\"\\n手动记忆管理演示:\")\n",
    "    \n",
    "    chain = ManualMemoryChain(llm)\n",
    "    \n",
    "    conversations = [\n",
    "        \"你好，我叫小明，是一名程序员\",\n",
    "        \"我在上海工作，主要做Python开发\",\n",
    "        \"你还记得我的名字吗？\",\n",
    "        \"我在哪个城市工作？\"\n",
    "    ]\n",
    "    \n",
    "    for i, user_input in enumerate(conversations, 1):\n",
    "        try:\n",
    "            response = chain.invoke(user_input)\n",
    "            print(f\"\\n第{i}轮:\")\n",
    "            print(f\"用户: {user_input}\")\n",
    "            print(f\"AI: {response}\")\n",
    "        except Exception as e:\n",
    "            print(f\"错误: {e}\")\n",
    "    \n",
    "    print(f\"\\n历史记录数量: {len(chain.get_history())} 条消息\")\n",
    "\n",
    "demo_manual_memory()\n"
   ],
   "id": "7fd10b6d3e3db875"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T12:57:48.903306Z",
     "start_time": "2025-07-21T12:57:29.410052Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===================== 方法2: 使用 RunnableWithMessageHistory =====================\n",
    "\n",
    "print(\"\\n\\n2. 使用 RunnableWithMessageHistory\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# 存储会话历史的字典\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    \"\"\"获取会话历史\"\"\"\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "# 创建基础链\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个友好的AI助手。请根据对话历史进行回复。\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "base_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# 添加消息历史\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    base_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\",\n",
    ")\n",
    "\n",
    "def demo_runnable_with_history():\n",
    "    \"\"\"演示 RunnableWithMessageHistory\"\"\"\n",
    "    print(\"\\nRunnableWithMessageHistory 演示:\")\n",
    "    \n",
    "    # 配置会话\n",
    "    config = {\"configurable\": {\"session_id\": \"demo_session\"}}\n",
    "    \n",
    "    conversations = [\n",
    "        \"你好，我是李华，我喜欢阅读\",\n",
    "        \"我最喜欢的书是《三体》\",\n",
    "        \"你还记得我的名字吗？\",\n",
    "        \"我喜欢什么书？\"\n",
    "    ]\n",
    "    \n",
    "    for i, user_input in enumerate(conversations, 1):\n",
    "        try:\n",
    "            response = chain_with_history.invoke(\n",
    "                {\"input\": user_input},\n",
    "                config=config\n",
    "            )\n",
    "            print(f\"\\n第{i}轮:\")\n",
    "            print(f\"用户: {user_input}\")\n",
    "            print(f\"AI: {response}\")\n",
    "        except Exception as e:\n",
    "            print(f\"错误: {e}\")\n",
    "    \n",
    "    # 显示历史\n",
    "    history = get_session_history(\"demo_session\")\n",
    "    print(f\"\\n会话历史: {len(history.messages)} 条消息\")\n",
    "\n",
    "demo_runnable_with_history()\n"
   ],
   "id": "35ddf3d4c87aadd0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2. 使用 RunnableWithMessageHistory\n",
      "----------------------------------------\n",
      "\n",
      "RunnableWithMessageHistory 演示:\n",
      "\n",
      "第1轮:\n",
      "用户: 你好，我是李华，我喜欢阅读\n",
      "AI: 你好李华，很高兴认识你！ 很高兴知道你喜欢阅读，那真是太棒了！ 你平时喜欢读什么类型的书呢？ 😊\n",
      "\n",
      "\n",
      "第2轮:\n",
      "用户: 我最喜欢的书是《三体》\n",
      "AI: AI: 《三体》！哇，刘慈欣的《三体》绝对是科幻经典！ 你喜欢它的什么呢？ 是刘慈欣的想象力，还是故事的深度，还是整个宇宙的宏大叙事？ 😊\n",
      "\n",
      "\n",
      "第3轮:\n",
      "用户: 你还记得我的名字吗？\n",
      "AI: AI: 当然记得！李华，很高兴再次和你聊天 😊 你今天过得怎么样？\n",
      "\n",
      "第4轮:\n",
      "用户: 我喜欢什么书？\n",
      "AI: AI: 你喜欢《三体》啊，看来你对科幻小说非常感兴趣！ 😊  之前我们聊过你喜欢阅读，而且你特别喜欢《三体》。  你觉得《三体》的什么吸引了你呢？ 还是说，你还记得我们之前聊过你喜欢阅读这件事呢？ 😉\n",
      "\n",
      "会话历史: 8 条消息\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ===================== 方法3: 带有记忆窗口的LCEL链 =====================\n",
    "\n",
    "print(\"\\n\\n3. 带有记忆窗口的LCEL链\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "class WindowMemoryChain:\n",
    "    \"\"\"带有窗口记忆的链\"\"\"\n",
    "    \n",
    "    def __init__(self, llm, window_size: int = 6):\n",
    "        self.llm = llm\n",
    "        self.window_size = window_size  # 保留的消息数量\n",
    "        self.history: List[BaseMessage] = []\n",
    "        \n",
    "        # 创建提示模板\n",
    "        self.prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"你是一个友好的AI助手。基于最近的对话历史进行回复。\"),\n",
    "            MessagesPlaceholder(variable_name=\"recent_history\"),\n",
    "            (\"human\", \"{input}\")\n",
    "        ])\n",
    "        \n",
    "        # 创建处理函数\n",
    "        def get_recent_history(inputs: dict) -> dict:\n",
    "            \"\"\"获取最近的历史记录\"\"\"\n",
    "            recent = self.history[-self.window_size:] if len(self.history) > self.window_size else self.history\n",
    "            return {\n",
    "                \"recent_history\": recent,\n",
    "                \"input\": inputs[\"input\"]\n",
    "            }\n",
    "        \n",
    "        # 创建链\n",
    "        self.chain = (\n",
    "            RunnableLambda(get_recent_history) |\n",
    "            self.prompt |\n",
    "            self.llm |\n",
    "            StrOutputParser()\n",
    "        )\n",
    "    \n",
    "    def invoke(self, user_input: str) -> str:\n",
    "        \"\"\"调用链\"\"\"\n",
    "        response = self.chain.invoke({\"input\": user_input})\n",
    "        \n",
    "        # 更新历史\n",
    "        self.history.append(HumanMessage(content=user_input))\n",
    "        self.history.append(AIMessage(content=response))\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def get_window_info(self) -> dict:\n",
    "        \"\"\"获取窗口信息\"\"\"\n",
    "        return {\n",
    "            \"total_messages\": len(self.history),\n",
    "            \"window_size\": self.window_size,\n",
    "            \"messages_in_window\": min(len(self.history), self.window_size)\n",
    "        }\n",
    "\n",
    "def demo_window_memory():\n",
    "    \"\"\"演示窗口记忆\"\"\"\n",
    "    print(\"\\n窗口记忆演示 (窗口大小=4):\")\n",
    "    \n",
    "    chain = WindowMemoryChain(llm, window_size=4)\n",
    "    \n",
    "    conversations = [\n",
    "        \"我叫张三，是医生\",\n",
    "        \"我在北京工作\",\n",
    "        \"我喜欢游泳\",\n",
    "        \"我有一只猫\",\n",
    "        \"我的猫叫小白\",\n",
    "        \"我还喜欢看电影\",\n",
    "        \"你还记得我的名字吗？\",  # 可能已经超出窗口\n",
    "        \"我的宠物是什么？\",      # 应该还记得\n",
    "    ]\n",
    "    \n",
    "    for i, user_input in enumerate(conversations, 1):\n",
    "        try:\n",
    "            response = chain.invoke(user_input)\n",
    "            print(f\"\\n第{i}轮:\")\n",
    "            print(f\"用户: {user_input}\")\n",
    "            print(f\"AI: {response}\")\n",
    "            \n",
    "            # 显示窗口信息\n",
    "            info = chain.get_window_info()\n",
    "            print(f\"窗口状态: {info['messages_in_window']}/{info['window_size']} (总计: {info['total_messages']})\")\n",
    "        except Exception as e:\n",
    "            print(f\"错误: {e}\")\n",
    "\n",
    "demo_window_memory()\n"
   ],
   "id": "bd75e622ad02465b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ===================== 方法4: 带有摘要功能的LCEL链 =====================\n",
    "\n",
    "print(\"\\n\\n4. 带有摘要功能的LCEL链\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "class SummaryMemoryChain:\n",
    "    \"\"\"带有摘要功能的记忆链\"\"\"\n",
    "    \n",
    "    def __init__(self, llm, max_messages: int = 8):\n",
    "        self.llm = llm\n",
    "        self.max_messages = max_messages\n",
    "        self.history: List[BaseMessage] = []\n",
    "        self.summary: str = \"\"\n",
    "        \n",
    "        # 主对话提示\n",
    "        self.chat_prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"你是一个友好的AI助手。\n",
    "\n",
    "{summary_context}\n",
    "\n",
    "请基于对话摘要和最近的对话历史进行回复。\"\"\"),\n",
    "            MessagesPlaceholder(variable_name=\"recent_history\"),\n",
    "            (\"human\", \"{input}\")\n",
    "        ])\n",
    "        \n",
    "        # 摘要提示\n",
    "        self.summary_prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"请简洁地总结以下对话的要点，保留重要信息：\"),\n",
    "            MessagesPlaceholder(variable_name=\"messages_to_summarize\"),\n",
    "            (\"human\", \"请提供对话摘要：\")\n",
    "        ])\n",
    "        \n",
    "        # 创建链\n",
    "        self.chat_chain = self.chat_prompt | self.llm | StrOutputParser()\n",
    "        self.summary_chain = self.summary_prompt | self.llm | StrOutputParser()\n",
    "    \n",
    "    def _create_summary(self, messages: List[BaseMessage]) -> str:\n",
    "        \"\"\"创建对话摘要\"\"\"\n",
    "        try:\n",
    "            return self.summary_chain.invoke({\n",
    "                \"messages_to_summarize\": messages\n",
    "            })\n",
    "        except:\n",
    "            return \"对话摘要生成失败\"\n",
    "    \n",
    "    def invoke(self, user_input: str) -> str:\n",
    "        \"\"\"调用链\"\"\"\n",
    "        # 如果历史太长，创建摘要\n",
    "        if len(self.history) >= self.max_messages:\n",
    "            # 摘要前面的消息\n",
    "            messages_to_summarize = self.history[:-4]  # 保留最近2轮对话\n",
    "            new_summary = self._create_summary(messages_to_summarize)\n",
    "            \n",
    "            # 更新摘要和历史\n",
    "            if self.summary:\n",
    "                self.summary = f\"{self.summary}\\n\\n{new_summary}\"\n",
    "            else:\n",
    "                self.summary = new_summary\n",
    "            \n",
    "            # 只保留最近的消息\n",
    "            self.history = self.history[-4:]\n",
    "        \n",
    "        # 准备上下文\n",
    "        summary_context = f\"对话摘要: {self.summary}\" if self.summary else \"这是对话的开始。\"\n",
    "        \n",
    "        # 调用聊天链\n",
    "        response = self.chat_chain.invoke({\n",
    "            \"summary_context\": summary_context,\n",
    "            \"recent_history\": self.history,\n",
    "            \"input\": user_input\n",
    "        })\n",
    "        \n",
    "        # 更新历史\n",
    "        self.history.append(HumanMessage(content=user_input))\n",
    "        self.history.append(AIMessage(content=response))\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def get_memory_info(self) -> dict:\n",
    "        \"\"\"获取记忆信息\"\"\"\n",
    "        return {\n",
    "            \"recent_messages\": len(self.history),\n",
    "            \"has_summary\": bool(self.summary),\n",
    "            \"summary_length\": len(self.summary) if self.summary else 0\n",
    "        }\n",
    "\n",
    "def demo_summary_memory():\n",
    "    \"\"\"演示摘要记忆\"\"\"\n",
    "    print(\"\\n摘要记忆演示 (最大消息数=6):\")\n",
    "    \n",
    "    chain = SummaryMemoryChain(llm, max_messages=6)\n",
    "    \n",
    "    conversations = [\n",
    "        \"我叫王五，是一名老师\",\n",
    "        \"我在上海的小学教数学\",\n",
    "        \"我有10年的教学经验\",\n",
    "        \"我喜欢和学生互动\",\n",
    "        \"我的班级有30个学生\",\n",
    "        \"我最近在准备期末考试\",\n",
    "        \"我还负责学校的数学竞赛\",\n",
    "        \"你还记得我的职业吗？\",\n",
    "        \"我在哪里工作？\",\n",
    "        \"我有多少年经验？\"\n",
    "    ]\n",
    "    \n",
    "    for i, user_input in enumerate(conversations, 1):\n",
    "        try:\n",
    "            response = chain.invoke(user_input)\n",
    "            print(f\"\\n第{i}轮:\")\n",
    "            print(f\"用户: {user_input}\")\n",
    "            print(f\"AI: {response}\")\n",
    "            \n",
    "            # 显示记忆信息\n",
    "            info = chain.get_memory_info()\n",
    "            print(f\"记忆状态: {info['recent_messages']} 条最近消息, 摘要: {'有' if info['has_summary'] else '无'}\")\n",
    "            \n",
    "            if info['has_summary'] and i % 3 == 0:  # 每3轮显示一次摘要\n",
    "                print(f\"当前摘要: {chain.summary[:100]}...\")\n",
    "        except Exception as e:\n",
    "            print(f\"错误: {e}\")\n",
    "\n",
    "demo_summary_memory()\n"
   ],
   "id": "88a67e0a03898d8c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ===================== 方法5: 多会话管理的LCEL实现 =====================\n",
    "\n",
    "print(\"\\n\\n5. 多会话管理的LCEL实现\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "class MultiSessionMemory:\n",
    "    \"\"\"多会话记忆管理\"\"\"\n",
    "    \n",
    "    def __init__(self, llm):\n",
    "        self.llm = llm\n",
    "        self.sessions: Dict[str, List[BaseMessage]] = {}\n",
    "        \n",
    "        # 创建提示模板\n",
    "        self.prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"你是一个友好的AI助手。请基于对话历史进行个性化回复。\"),\n",
    "            MessagesPlaceholder(variable_name=\"history\"),\n",
    "            (\"human\", \"{input}\")\n",
    "        ])\n",
    "        \n",
    "        # 创建链\n",
    "        self.chain = self.prompt | self.llm | StrOutputParser()\n",
    "    \n",
    "    def invoke(self, user_input: str, session_id: str) -> str:\n",
    "        \"\"\"为特定会话调用链\"\"\"\n",
    "        # 获取或创建会话历史\n",
    "        if session_id not in self.sessions:\n",
    "            self.sessions[session_id] = []\n",
    "        \n",
    "        history = self.sessions[session_id]\n",
    "        \n",
    "        # 调用链\n",
    "        response = self.chain.invoke({\n",
    "            \"history\": history,\n",
    "            \"input\": user_input\n",
    "        })\n",
    "        \n",
    "        # 更新会话历史\n",
    "        history.append(HumanMessage(content=user_input))\n",
    "        history.append(AIMessage(content=response))\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def get_session_info(self) -> dict:\n",
    "        \"\"\"获取会话信息\"\"\"\n",
    "        return {\n",
    "            \"total_sessions\": len(self.sessions),\n",
    "            \"session_ids\": list(self.sessions.keys()),\n",
    "            \"messages_per_session\": {\n",
    "                sid: len(messages) for sid, messages in self.sessions.items()\n",
    "            }\n",
    "        }\n",
    "\n",
    "def demo_multi_session():\n",
    "    \"\"\"演示多会话管理\"\"\"\n",
    "    print(\"\\n多会话管理演示:\")\n",
    "    \n",
    "    memory = MultiSessionMemory(llm)\n",
    "    \n",
    "    # 用户A的对话\n",
    "    print(\"\\n=== 用户A的会话 ===\")\n",
    "    response1 = memory.invoke(\"我是Alice，我喜欢画画\", \"user_a\")\n",
    "    print(f\"Alice: 我是Alice，我喜欢画画\")\n",
    "    print(f\"AI: {response1}\")\n",
    "    \n",
    "    # 用户B的对话\n",
    "    print(\"\\n=== 用户B的会话 ===\")\n",
    "    response2 = memory.invoke(\"我是Bob，我是程序员\", \"user_b\")\n",
    "    print(f\"Bob: 我是Bob，我是程序员\")\n",
    "    print(f\"AI: {response2}\")\n",
    "    \n",
    "    # 继续用户A的对话\n",
    "    print(\"\\n=== 继续Alice的会话 ===\")\n",
    "    response3 = memory.invoke(\"你记得我的爱好吗？\", \"user_a\")\n",
    "    print(f\"Alice: 你记得我的爱好吗？\")\n",
    "    print(f\"AI: {response3}\")\n",
    "    \n",
    "    # 继续用户B的对话\n",
    "    print(\"\\n=== 继续Bob的会话 ===\")\n",
    "    response4 = memory.invoke(\"我的职业是什么？\", \"user_b\")\n",
    "    print(f\"Bob: 我的职业是什么？\")\n",
    "    print(f\"AI: {response4}\")\n",
    "    \n",
    "    # 显示会话信息\n",
    "    info = memory.get_session_info()\n",
    "    print(f\"\\n会话统计: {info}\")\n",
    "\n",
    "demo_multi_session()\n"
   ],
   "id": "a2ace54b3ee32d97"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ===================== 总结和对比 =====================\n",
    "\n",
    "print(\"\\n\\n\" + \"=\"*60)\n",
    "print(\"LCEL 对话记忆实现方法总结\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "summary_text = \"\"\"\n",
    "LCEL 实现对话记忆的方法:\n",
    "\n",
    "1. 🔧 手动管理历史\n",
    "   优点: 完全控制，简单直接\n",
    "   缺点: 需要手动管理状态\n",
    "   适用: 简单应用，学习目的\n",
    "\n",
    "2. 📚 RunnableWithMessageHistory\n",
    "   优点: 官方支持，功能完整\n",
    "   缺点: API相对复杂\n",
    "   适用: 标准聊天应用\n",
    "\n",
    "3. 🪟 窗口记忆\n",
    "   优点: 内存使用固定\n",
    "   缺点: 会丢失早期信息\n",
    "   适用: 长对话，内存有限\n",
    "\n",
    "4. 📝 摘要记忆\n",
    "   优点: 保留重要信息，适合长对话\n",
    "   缺点: 需要额外LLM调用\n",
    "   适用: 超长对话，成本敏感\n",
    "\n",
    "5. 👥 多会话管理\n",
    "   优点: 支持多用户\n",
    "   缺点: 需要手动实现会话隔离\n",
    "   适用: 多用户应用\n",
    "\n",
    "选择建议:\n",
    "- 简单聊天: 方法1或2\n",
    "- 长对话: 方法3或4\n",
    "- 多用户: 方法5\n",
    "- 复杂应用: 考虑迁移到LangGraph\n",
    "\n",
    "注意: LangChain 0.3+ 推荐使用 LangGraph 来处理复杂的记忆需求！\n",
    "\"\"\"\n",
    "\n",
    "print(summary_text)\n",
    "\n",
    "print(\"\\n演示完成！\")\n",
    "print(\"虽然LCEL可以实现记忆功能，但对于复杂应用建议使用LangGraph。\")\n"
   ],
   "id": "5718b4a843cc784e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ===================== 交互式演示 =====================\n",
    "\n",
    "def interactive_lcel_demo():\n",
    "    \"\"\"交互式LCEL记忆演示\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"交互式LCEL记忆演示\")\n",
    "    print(\"选择一种记忆实现方式进行测试\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    print(\"\\n可用的记忆实现:\")\n",
    "    print(\"1. 手动管理历史\")\n",
    "    print(\"2. RunnableWithMessageHistory\")\n",
    "    print(\"3. 窗口记忆\")\n",
    "    print(\"4. 摘要记忆\")\n",
    "    print(\"5. 多会话管理\")\n",
    "\n",
    "    choice = input(\"\\n请选择实现方式 (1-5): \").strip()\n",
    "\n",
    "    if choice == \"1\":\n",
    "        chain = ManualMemoryChain(llm)\n",
    "        print(\"\\n使用手动管理历史，输入 'quit' 退出\")\n",
    "\n",
    "        while True:\n",
    "            user_input = input(\"\\n你: \").strip()\n",
    "            if user_input.lower() == 'quit':\n",
    "                break\n",
    "            try:\n",
    "                response = chain.invoke(user_input)\n",
    "                print(f\"AI: {response}\")\n",
    "            except Exception as e:\n",
    "                print(f\"错误: {e}\")\n",
    "\n",
    "    elif choice == \"2\":\n",
    "        config = {\"configurable\": {\"session_id\": \"interactive\"}}\n",
    "        print(\"\\n使用 RunnableWithMessageHistory，输入 'quit' 退出\")\n",
    "\n",
    "        while True:\n",
    "            user_input = input(\"\\n你: \").strip()\n",
    "            if user_input.lower() == 'quit':\n",
    "                break\n",
    "            try:\n",
    "                response = chain_with_history.invoke(\n",
    "                    {\"input\": user_input}, config=config\n",
    "                )\n",
    "                print(f\"AI: {response}\")\n",
    "            except Exception as e:\n",
    "                print(f\"错误: {e}\")\n",
    "\n",
    "    elif choice == \"3\":\n",
    "        chain = WindowMemoryChain(llm, window_size=6)\n",
    "        print(\"\\n使用窗口记忆 (窗口大小=6)，输入 'quit' 退出\")\n",
    "\n",
    "        while True:\n",
    "            user_input = input(\"\\n你: \").strip()\n",
    "            if user_input.lower() == 'quit':\n",
    "                break\n",
    "            try:\n",
    "                response = chain.invoke(user_input)\n",
    "                print(f\"AI: {response}\")\n",
    "                info = chain.get_window_info()\n",
    "                print(f\"[窗口: {info['messages_in_window']}/{info['window_size']}]\")\n",
    "            except Exception as e:\n",
    "                print(f\"错误: {e}\")\n",
    "\n",
    "    elif choice == \"4\":\n",
    "        chain = SummaryMemoryChain(llm, max_messages=8)\n",
    "        print(\"\\n使用摘要记忆 (最大消息=8)，输入 'quit' 退出\")\n",
    "\n",
    "        while True:\n",
    "            user_input = input(\"\\n你: \").strip()\n",
    "            if user_input.lower() == 'quit':\n",
    "                break\n",
    "            try:\n",
    "                response = chain.invoke(user_input)\n",
    "                print(f\"AI: {response}\")\n",
    "                info = chain.get_memory_info()\n",
    "                print(f\"[消息: {info['recent_messages']}, 摘要: {'有' if info['has_summary'] else '无'}]\")\n",
    "            except Exception as e:\n",
    "                print(f\"错误: {e}\")\n",
    "\n",
    "    elif choice == \"5\":\n",
    "        memory = MultiSessionMemory(llm)\n",
    "        session_id = input(\"请输入会话ID: \").strip() or \"default\"\n",
    "        print(f\"\\n使用多会话管理 (会话: {session_id})，输入 'quit' 退出，输入 'switch' 切换会话\")\n",
    "\n",
    "        while True:\n",
    "            user_input = input(\"\\n你: \").strip()\n",
    "            if user_input.lower() == 'quit':\n",
    "                break\n",
    "            elif user_input.lower() == 'switch':\n",
    "                session_id = input(\"请输入新的会话ID: \").strip() or \"default\"\n",
    "                print(f\"切换到会话: {session_id}\")\n",
    "                continue\n",
    "            try:\n",
    "                response = memory.invoke(user_input, session_id)\n",
    "                print(f\"AI: {response}\")\n",
    "                info = memory.get_session_info()\n",
    "                print(f\"[会话: {session_id}, 总会话数: {info['total_sessions']}]\")\n",
    "            except Exception as e:\n",
    "                print(f\"错误: {e}\")\n",
    "    else:\n",
    "        print(\"无效选择\")\n",
    "\n",
    "# 如果直接运行此文件，启动交互式演示\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # 测试连接\n",
    "        test_response = llm.invoke(\"Hello\")\n",
    "        print(\"✓ Ollama 连接成功\")\n",
    "        interactive_lcel_demo()\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Ollama 连接失败: {e}\")\n",
    "        print(\"请确保 Ollama 正在运行: ollama serve\")\n",
    "        print(\"并安装模型: ollama pull gemma:3b\")\n"
   ],
   "id": "40306f2d82d186f7"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
