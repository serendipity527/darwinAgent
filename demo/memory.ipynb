{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T11:50:36.429159Z",
     "start_time": "2025-07-21T11:50:36.307891Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "LangChain 记忆对话系统演示\n",
    "展示不同类型的记忆机制在对话中的应用\n",
    "\n",
    "包含以下记忆类型：\n",
    "1. ConversationBufferMemory - 基础缓冲记忆\n",
    "2. ConversationBufferWindowMemory - 窗口缓冲记忆\n",
    "3. ConversationSummaryMemory - 摘要记忆\n",
    "4. ConversationSummaryBufferMemory - 摘要缓冲记忆\n",
    "5. ConversationTokenBufferMemory - 基于token的缓冲记忆\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import asyncio\n",
    "from typing import Dict, List, Any, Optional\n",
    "from datetime import datetime\n",
    "\n",
    "# LangChain imports\n",
    "from langchain.memory import (\n",
    "    ConversationBufferMemory,\n",
    "    ConversationBufferWindowMemory,\n",
    "    ConversationSummaryMemory,\n",
    "    ConversationSummaryBufferMemory,\n",
    "    ConversationTokenBufferMemory,\n",
    "    ChatMessageHistory\n",
    ")\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_ollama import OllamaLLM  # 使用新的导入\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 设置环境变量（如果需要使用OpenAI）\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key-here\"\n",
    "\n",
    "print(\"LangChain 记忆对话系统演示\")\n",
    "print(\"=\" * 50)\n"
   ],
   "id": "587a1b13b8c1484a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain 记忆对话系统演示\n",
      "==================================================\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T11:50:38.658693Z",
     "start_time": "2025-07-21T11:50:38.611783Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===================== 配置部分 =====================\n",
    "\n",
    "# 模型配置\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434\"\n",
    "OLLAMA_MODEL = \"gemma3:4b\"  # 或者其他已安装的模型\n",
    "\n",
    "# 创建LLM实例\n",
    "def create_llm(use_openai: bool = False):\n",
    "    \"\"\"\n",
    "    创建语言模型实例\n",
    "\n",
    "    Args:\n",
    "        use_openai: 是否使用OpenAI模型\n",
    "\n",
    "    Returns:\n",
    "        LLM实例\n",
    "    \"\"\"\n",
    "    if use_openai:\n",
    "        # 使用OpenAI模型\n",
    "        return ChatOpenAI(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            temperature=0.7,\n",
    "            max_tokens=1000\n",
    "        )\n",
    "    else:\n",
    "        # 使用本地Ollama模型\n",
    "        return OllamaLLM(\n",
    "            base_url=OLLAMA_BASE_URL,\n",
    "            model=OLLAMA_MODEL,\n",
    "            temperature=0.7\n",
    "        )\n",
    "\n",
    "# 创建LLM实例（默认使用Ollama）\n",
    "llm = create_llm(use_openai=False)\n",
    "\n",
    "print(f\"使用模型: {OLLAMA_MODEL}\")\n",
    "print(f\"Ollama地址: {OLLAMA_BASE_URL}\")\n"
   ],
   "id": "6232111e5f7d47da",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用模型: gemma3:4b\n",
      "Ollama地址: http://localhost:11434\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T11:49:25.619467Z",
     "start_time": "2025-07-21T11:48:32.001655Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===================== 1. ConversationBufferMemory 演示 =====================\n",
    "\n",
    "print(\"\\n1. ConversationBufferMemory - 基础缓冲记忆\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# 创建基础缓冲记忆\n",
    "buffer_memory = ConversationBufferMemory(\n",
    "    return_messages=True,  # 返回消息对象而不是字符串\n",
    "    memory_key=\"history\"  # 记忆在prompt中的键名，使用默认的\"history\"\n",
    ")\n",
    "\n",
    "# 创建自定义prompt模板以确保兼容性\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "buffer_prompt = PromptTemplate(\n",
    "    input_variables=[\"history\", \"input\"],\n",
    "    template=\"\"\"以下是人类和AI之间的友好对话。AI很健谈，并根据其上下文提供大量具体细节。如果AI不知道问题的答案，它会诚实地说不知道。\n",
    "\n",
    "当前对话:\n",
    "{history}\n",
    "人类: {input}\n",
    "AI:\"\"\"\n",
    ")\n",
    "\n",
    "# 创建对话链\n",
    "conversation_buffer = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=buffer_memory,\n",
    "    prompt=buffer_prompt,\n",
    "    # verbose=True  # 显示详细信息\n",
    ")\n",
    "\n",
    "print(\"ConversationBufferMemory 特点:\")\n",
    "print(\"- 保存完整的对话历史\")\n",
    "print(\"- 记忆会随着对话增长而增长\")\n",
    "print(\"- 适合短对话或记忆容量充足的场景\")\n",
    "\n",
    "# 模拟对话\n",
    "def demo_buffer_memory():\n",
    "    \"\"\"演示基础缓冲记忆\"\"\"\n",
    "    print(\"\\n开始对话演示...\")\n",
    "\n",
    "    # 第一轮对话\n",
    "    response1 = conversation_buffer.predict(input=\"你好，我叫张三，我是一名软件工程师\")\n",
    "    print(f\"用户: 你好，我叫张三，我是一名软件工程师\")\n",
    "    print(f\"AI: {response1}\")\n",
    "\n",
    "    # 第二轮对话\n",
    "    response2 = conversation_buffer.predict(input=\"我喜欢编程和阅读技术书籍\")\n",
    "    print(f\"\\n用户: 我喜欢编程和阅读技术书籍\")\n",
    "    print(f\"AI: {response2}\")\n",
    "\n",
    "    # 第三轮对话 - 测试记忆\n",
    "    response3 = conversation_buffer.predict(input=\"你还记得我的名字和职业吗？\")\n",
    "    print(f\"\\n用户: 你还记得我的名字和职业吗？\")\n",
    "    print(f\"AI: {response3}\")\n",
    "\n",
    "    # 查看记忆内容\n",
    "    print(f\"\\n当前记忆内容:\")\n",
    "    print(f\"记忆变量: {buffer_memory.memory_key}\")\n",
    "    print(f\"记忆内容: {buffer_memory.chat_memory.messages}\")\n",
    "\n",
    "# 运行演示\n",
    "demo_buffer_memory()\n"
   ],
   "id": "dccfeba8f9e247a8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. ConversationBufferMemory - 基础缓冲记忆\n",
      "----------------------------------------\n",
      "ConversationBufferMemory 特点:\n",
      "- 保存完整的对话历史\n",
      "- 记忆会随着对话增长而增长\n",
      "- 适合短对话或记忆容量充足的场景\n",
      "\n",
      "开始对话演示...\n",
      "用户: 你好，我叫张三，我是一名软件工程师\n",
      "AI: 你好，张三！很高兴认识你。作为一名软件工程师，你可能从事各种各样的项目吧？ 我注意到软件工程是一个非常广泛的领域，涵盖了从前端开发（例如使用React、Angular或Vue.js构建用户界面）到后端开发（例如使用Node.js、Python或Java构建服务器端逻辑）再到数据库管理（例如MySQL、PostgreSQL或MongoDB）以及 DevOps 实践（例如使用Docker、Kubernetes和AWS）。\n",
      "\n",
      "你更专注于哪方面？你主要使用哪些编程语言和技术栈？  或者，你目前正在处理什么类型的项目？ 告诉我更多关于你的工作内容，我很高兴了解！\n",
      "\n",
      "\n",
      "用户: 我喜欢编程和阅读技术书籍\n",
      "AI: AI: 哇，编程和阅读技术书籍，这真是个好爱好！这表明你对技术有持续的学习兴趣，这在软件工程领域至关重要。你喜欢阅读什么样的技术书籍呢？ 是关于算法和数据结构，或者面向对象编程，还是更偏向于特定编程语言的深入指南？\n",
      "\n",
      "我注意到，技术书籍通常会深入探讨特定的技术领域。例如，像“算法导论”这样的书会让你掌握排序、搜索和动态规划等核心算法，而像“深入理解 JavaScript”这样的书则会让你对 JavaScript 的内部机制有更全面的理解。 \n",
      "\n",
      "另外，你可能也对设计模式感兴趣，比如工厂模式、单例模式等等。 这些模式可以帮助你编写更易于维护和扩展的代码。\n",
      "\n",
      "你最近读过哪些技术书籍？ 或者，你最喜欢的编程书籍有哪些？ 告诉我一些你觉得特别有价值的书籍，我很乐意和您讨论！ 另外，你最喜欢用哪种编程语言呢？ 比如，C++、Python、Java、JavaScript？\n",
      "\n",
      "\n",
      "用户: 你还记得我的名字和职业吗？\n",
      "AI: AI: 当然记得！你的名字是张三，是一名软件工程师。很高兴再次见到你！你对软件工程的兴趣和对技术书籍的热爱让我对你有了更深入的了解。现在，你有什么想进一步探讨的吗？例如，你最近在学习什么新的技术，或者你对某个特定的编程语言或技术栈有什么看法？或者，你想聊聊你最近读过的技术书籍呢？ 让我知道你现在最感兴趣的话题！\n",
      "\n",
      "\n",
      "当前记忆内容:\n",
      "记忆变量: history\n",
      "记忆内容: [HumanMessage(content='你好，我叫张三，我是一名软件工程师', additional_kwargs={}, response_metadata={}), AIMessage(content='你好，张三！很高兴认识你。作为一名软件工程师，你可能从事各种各样的项目吧？ 我注意到软件工程是一个非常广泛的领域，涵盖了从前端开发（例如使用React、Angular或Vue.js构建用户界面）到后端开发（例如使用Node.js、Python或Java构建服务器端逻辑）再到数据库管理（例如MySQL、PostgreSQL或MongoDB）以及 DevOps 实践（例如使用Docker、Kubernetes和AWS）。\\n\\n你更专注于哪方面？你主要使用哪些编程语言和技术栈？  或者，你目前正在处理什么类型的项目？ 告诉我更多关于你的工作内容，我很高兴了解！\\n', additional_kwargs={}, response_metadata={}), HumanMessage(content='我喜欢编程和阅读技术书籍', additional_kwargs={}, response_metadata={}), AIMessage(content='AI: 哇，编程和阅读技术书籍，这真是个好爱好！这表明你对技术有持续的学习兴趣，这在软件工程领域至关重要。你喜欢阅读什么样的技术书籍呢？ 是关于算法和数据结构，或者面向对象编程，还是更偏向于特定编程语言的深入指南？\\n\\n我注意到，技术书籍通常会深入探讨特定的技术领域。例如，像“算法导论”这样的书会让你掌握排序、搜索和动态规划等核心算法，而像“深入理解 JavaScript”这样的书则会让你对 JavaScript 的内部机制有更全面的理解。 \\n\\n另外，你可能也对设计模式感兴趣，比如工厂模式、单例模式等等。 这些模式可以帮助你编写更易于维护和扩展的代码。\\n\\n你最近读过哪些技术书籍？ 或者，你最喜欢的编程书籍有哪些？ 告诉我一些你觉得特别有价值的书籍，我很乐意和您讨论！ 另外，你最喜欢用哪种编程语言呢？ 比如，C++、Python、Java、JavaScript？\\n', additional_kwargs={}, response_metadata={}), HumanMessage(content='你还记得我的名字和职业吗？', additional_kwargs={}, response_metadata={}), AIMessage(content='AI: 当然记得！你的名字是张三，是一名软件工程师。很高兴再次见到你！你对软件工程的兴趣和对技术书籍的热爱让我对你有了更深入的了解。现在，你有什么想进一步探讨的吗？例如，你最近在学习什么新的技术，或者你对某个特定的编程语言或技术栈有什么看法？或者，你想聊聊你最近读过的技术书籍呢？ 让我知道你现在最感兴趣的话题！\\n', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T11:54:12.308348Z",
     "start_time": "2025-07-21T11:51:29.285474Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===================== 2. ConversationBufferWindowMemory 演示 =====================\n",
    "\n",
    "print(\"\\n\\n2. ConversationBufferWindowMemory - 窗口缓冲记忆\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# 创建窗口缓冲记忆（只保留最近2轮对话）\n",
    "window_memory = ConversationBufferWindowMemory(\n",
    "    k=2,  # 保留最近2轮对话\n",
    "    return_messages=True,\n",
    "    memory_key=\"history\"  # 使用默认的\"history\"\n",
    ")\n",
    "\n",
    "# 创建对话链\n",
    "conversation_window = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=window_memory,\n",
    "    prompt=buffer_prompt,  # 使用相同的prompt模板\n",
    "    max_tokens_limit=100,  # 设置最大token数\n",
    "    # verbose=True\n",
    ")\n",
    "\n",
    "print(\"ConversationBufferWindowMemory 特点:\")\n",
    "print(\"- 只保留最近k轮对话\")\n",
    "print(\"- 记忆大小固定，不会无限增长\")\n",
    "print(\"- 适合长对话场景\")\n",
    "print(f\"- 当前设置: k={window_memory.k}\")\n",
    "\n",
    "def demo_window_memory():\n",
    "    \"\"\"演示窗口缓冲记忆\"\"\"\n",
    "    print(\"\\n开始对话演示...\")\n",
    "\n",
    "    # 多轮对话\n",
    "    conversations = [\n",
    "        \"我叫李四，是一名数据科学家\",\n",
    "        \"我在北京工作\",\n",
    "        \"我喜欢机器学习和深度学习\",\n",
    "        \"我最近在研究大语言模型\",\n",
    "        \"你还记得我的名字吗？\",  # 这时应该忘记了最初的信息\n",
    "        \"你还记得我在哪里工作吗？\"  # 这个信息可能还记得\n",
    "    ]\n",
    "\n",
    "    for i, user_input in enumerate(conversations, 1):\n",
    "        response = conversation_window.predict(input=user_input)\n",
    "        print(f\"\\n第{i}轮对话:\")\n",
    "        print(f\"用户: {user_input}\")\n",
    "        print(f\"AI: {response}\")\n",
    "\n",
    "        # 显示当前窗口内容\n",
    "        messages = window_memory.chat_memory.messages\n",
    "        print(f\"当前窗口大小: {len(messages)//2} 轮对话\")\n",
    "\n",
    "    print(f\"\\n最终记忆内容 (最近{window_memory.k}轮):\")\n",
    "    for msg in window_memory.chat_memory.messages:\n",
    "        role = \"用户\" if isinstance(msg, HumanMessage) else \"AI\"\n",
    "        print(f\"{role}: {msg.content}\")\n",
    "\n",
    "# 运行演示\n",
    "demo_window_memory()\n"
   ],
   "id": "74309afd7633f93",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2. ConversationBufferWindowMemory - 窗口缓冲记忆\n",
      "--------------------------------------------------\n",
      "ConversationBufferWindowMemory 特点:\n",
      "- 只保留最近k轮对话\n",
      "- 记忆大小固定，不会无限增长\n",
      "- 适合长对话场景\n",
      "- 当前设置: k=2\n",
      "\n",
      "开始对话演示...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\34769\\AppData\\Local\\Temp\\ipykernel_35128\\298349334.py:7: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  window_memory = ConversationBufferWindowMemory(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "第1轮对话:\n",
      "用户: 我叫李四，是一名数据科学家\n",
      "AI: 好的李四，很高兴认识你！作为一名数据科学家，这真是个非常有趣且充满挑战的领域。 \n",
      "\n",
      "让我先简单介绍一下我自己。我是一个大型语言模型，由 Google 训练。我的核心功能是理解和生成人类语言。我所掌握的信息量非常庞大，涵盖了从历史、科学、文化到艺术等各个方面。\n",
      "\n",
      "作为数据科学家，你可能经常接触到各种数据分析、建模和可视化任务。你可能使用 Python、R 这样的编程语言，以及像 Pandas、Scikit-learn、TensorFlow 这样的工具。  你可能也需要处理各种数据格式，比如 CSV、JSON、SQL 数据库等等。 \n",
      "\n",
      "你对哪些具体的领域感兴趣呢？ 例如，你主要从事什么类型的项目？  你是侧重于预测分析、机器学习、自然语言处理，还是其他方面？ 告诉我你的工作内容，我可以尝试提供更多相关的知识和信息。\n",
      "\n",
      "当前窗口大小: 1 轮对话\n",
      "\n",
      "第2轮对话:\n",
      "用户: 我在北京工作\n",
      "AI: 好的，李四，在北京工作真是太棒了！北京作为中国的政治、文化和科技中心，数据科学领域也发展非常活跃。\n",
      "\n",
      "考虑到你在北京工作，我能提供一些关于北京数据科学领域的信息：\n",
      "\n",
      "*   **主要行业:** 北京的数据科学应用领域非常广泛，包括但不限于：\n",
      "    *   **金融:** 许多银行和金融机构都在北京进行大数据分析、风险管理、欺诈检测等工作。例如，中国工商银行、招商银行等都有大型数据科学团队。\n",
      "    *   **科技:** 百度、腾讯、阿里巴巴等巨头公司在北京都有大量的研发中心和数据科学团队，主要从事搜索引擎优化、推荐系统、广告投放等方向。\n",
      "    *   **政府:** 北京市政府也大力推动大数据治理，利用数据分析来提升城市管理水平，例如交通优化、环境监测、公共安全等方面。\n",
      "    *   **医疗:** 北京拥有清华大学和北京大学等顶尖学府，在生物医学大数据分析、基因组学、新药研发等方面都有着很强的实力。\n",
      "    *   **消费电子:**  华策方舟、小米等公司在北京都有着大量的数据科学团队，主要从事用户行为分析、产品优化、市场营销等方向。\n",
      "\n",
      "*   **常用技术栈:** 鉴于你在北京工作，我推测你可能使用以下技术栈：\n",
      "    *   **编程语言:** Python (尤其 Pandas, Scikit-learn) 是数据科学领域最常用的语言。\n",
      "    *   **大数据技术:** Hadoop, Spark, Hive 等用于处理和分析大规模数据集。\n",
      "    *   **云计算平台:** 阿里云、腾讯云、华为云等，提供计算、存储、数据库等服务。\n",
      "    *   **数据库:**  MySQL, PostgreSQL, MongoDB 等。\n",
      "\n",
      "*   **一些具体的项目例子:**\n",
      "    *   **交通优化:**  利用大数据分析交通流量，优化红绿灯配时，缓解交通拥堵。\n",
      "    *   **精准营销:**  基于用户行为数据，进行个性化推荐和精准广告投放。\n",
      "    *   **公共安全:**  利用视频监控数据和行为分析技术，预防和打击犯罪。\n",
      "\n",
      "  为了更好地帮助你，你能否告诉我：\n",
      "\n",
      "    *   你主要在哪个行业工作？\n",
      "    *   你主要负责哪些类型的项目？\n",
      "    *   你目前使用哪些具体的工具和技术？\n",
      "当前窗口大小: 2 轮对话\n",
      "\n",
      "第3轮对话:\n",
      "用户: 我喜欢机器学习和深度学习\n",
      "AI: 好的，李四，很高兴你对机器学习和深度学习感兴趣！这确实是当前数据科学领域最热门和最具发展潜力的方向之一。 它们在解决复杂问题和创造新的应用方面都具有巨大的潜力。\n",
      "\n",
      "让我来详细说说机器学习和深度学习的一些关键方面，并结合你可能感兴趣的领域：\n",
      "\n",
      "**1. 机器学习 (Machine Learning - ML)**\n",
      "\n",
      "*   **定义:** 机器学习是一种让计算机在没有明确编程的情况下学习的方法。 计算机通过分析数据来识别模式，然后利用这些模式进行预测或决策。\n",
      "*   **常见算法:**\n",
      "    *   **线性回归和逻辑回归:**  用于预测连续值和二元分类问题。\n",
      "    *   **决策树和随机森林:**  用于分类和回归，易于解释和理解。\n",
      "    *   **支持向量机 (SVM):**  一种强大的分类算法，特别适合处理高维数据。\n",
      "    *   **K-近邻算法 (KNN):**  一种简单的分类算法，基于距离进行分类。\n",
      "*   **应用领域:**  推荐系统、欺诈检测、信用评分、自然语言处理等。\n",
      "\n",
      "**2. 深度学习 (Deep Learning - DL)**\n",
      "\n",
      "*   **定义:** 深度学习是机器学习的一个子集，它使用人工神经网络 (Artificial Neural Networks - ANNs) 来学习数据中的复杂模式。 深度学习模型通常由多层神经网络组成，每一层都提取数据的不同特征。\n",
      "*   **常见模型:**\n",
      "    *   **卷积神经网络 (CNNs):**  在图像识别和计算机视觉领域表现出色。\n",
      "    *   **循环神经网络 (RNNs):**  在处理序列数据 (例如文本、语音、时间序列) 方面表现出色。\n",
      "    *   **Transformer 网络:**  目前在自然语言处理领域占据主导地位，例如 BERT、GPT 系列模型。\n",
      "*   **应用领域:**  图像识别、语音识别、自然语言处理、机器翻译、自动驾驶等。\n",
      "\n",
      "**深度学习与机器学习的关系:** 深度学习可以看作是机器学习的一个更高级的形式，它通常需要更大的数据集和更强大的计算能力。\n",
      "\n",
      "**考虑到你对深度学习的兴趣，以下是一些你可能感兴趣的进一步学习方向:**\n",
      "\n",
      "*   **TensorFlow 和 PyTorch:**  这是目前最流行的深度学习框架，你可以使用它们来构建和训练自己的模型。\n",
      "*   **自然语言处理 (NLP):**  利用深度学习技术处理文本数据，例如情感分析、文本生成、机器翻译等。\n",
      "*   **计算机视觉:**  利用深度学习技术处理图像和视频数据，例如目标检测、图像分割、人脸识别等。\n",
      "\n",
      "**为了更好地帮助你，你能否告诉我：**\n",
      "\n",
      "*   你对深度学习的具体哪个方向更感兴趣？(例如，计算机视觉、自然语言处理，还是其他领域？)\n",
      "*   你目前在学习或使用哪些深度学习相关的工具和技术？\n",
      "*   你希望通过学习深度学习解决什么样的问题？\n",
      "\n",
      "当前窗口大小: 3 轮对话\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 57\u001B[39m\n\u001B[32m     54\u001B[39m         \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrole\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmsg.content\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m     56\u001B[39m \u001B[38;5;66;03m# 运行演示\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m57\u001B[39m \u001B[43mdemo_window_memory\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 42\u001B[39m, in \u001B[36mdemo_window_memory\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m     32\u001B[39m conversations = [\n\u001B[32m     33\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33m我叫李四，是一名数据科学家\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     34\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33m我在北京工作\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m     38\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33m你还记得我在哪里工作吗？\u001B[39m\u001B[33m\"\u001B[39m  \u001B[38;5;66;03m# 这个信息可能还记得\u001B[39;00m\n\u001B[32m     39\u001B[39m ]\n\u001B[32m     41\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i, user_input \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(conversations, \u001B[32m1\u001B[39m):\n\u001B[32m---> \u001B[39m\u001B[32m42\u001B[39m     response = \u001B[43mconversation_window\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m=\u001B[49m\u001B[43muser_input\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     43\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m第\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m轮对话:\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     44\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m用户: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00muser_input\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\javaDevelopment\\program_project\\Pycharm_project\\darwinAgent\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py:319\u001B[39m, in \u001B[36mLLMChain.predict\u001B[39m\u001B[34m(self, callbacks, **kwargs)\u001B[39m\n\u001B[32m    304\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mpredict\u001B[39m(\u001B[38;5;28mself\u001B[39m, callbacks: Callbacks = \u001B[38;5;28;01mNone\u001B[39;00m, **kwargs: Any) -> \u001B[38;5;28mstr\u001B[39m:\n\u001B[32m    305\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Format prompt with kwargs and pass to LLM.\u001B[39;00m\n\u001B[32m    306\u001B[39m \n\u001B[32m    307\u001B[39m \u001B[33;03m    Args:\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    317\u001B[39m \u001B[33;03m            completion = llm.predict(adjective=\"funny\")\u001B[39;00m\n\u001B[32m    318\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m319\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;28mself\u001B[39m.output_key]\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\javaDevelopment\\program_project\\Pycharm_project\\darwinAgent\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:189\u001B[39m, in \u001B[36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    187\u001B[39m     warned = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m    188\u001B[39m     emit_warning()\n\u001B[32m--> \u001B[39m\u001B[32m189\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mwrapped\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\javaDevelopment\\program_project\\Pycharm_project\\darwinAgent\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py:386\u001B[39m, in \u001B[36mChain.__call__\u001B[39m\u001B[34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001B[39m\n\u001B[32m    354\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Execute the chain.\u001B[39;00m\n\u001B[32m    355\u001B[39m \n\u001B[32m    356\u001B[39m \u001B[33;03mArgs:\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    377\u001B[39m \u001B[33;03m        `Chain.output_keys`.\u001B[39;00m\n\u001B[32m    378\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    379\u001B[39m config = {\n\u001B[32m    380\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mcallbacks\u001B[39m\u001B[33m\"\u001B[39m: callbacks,\n\u001B[32m    381\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mtags\u001B[39m\u001B[33m\"\u001B[39m: tags,\n\u001B[32m    382\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mmetadata\u001B[39m\u001B[33m\"\u001B[39m: metadata,\n\u001B[32m    383\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mrun_name\u001B[39m\u001B[33m\"\u001B[39m: run_name,\n\u001B[32m    384\u001B[39m }\n\u001B[32m--> \u001B[39m\u001B[32m386\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    387\u001B[39m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    388\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcast\u001B[49m\u001B[43m(\u001B[49m\u001B[43mRunnableConfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43mk\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mitems\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    389\u001B[39m \u001B[43m    \u001B[49m\u001B[43mreturn_only_outputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreturn_only_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    390\u001B[39m \u001B[43m    \u001B[49m\u001B[43minclude_run_info\u001B[49m\u001B[43m=\u001B[49m\u001B[43minclude_run_info\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    391\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\javaDevelopment\\program_project\\Pycharm_project\\darwinAgent\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py:167\u001B[39m, in \u001B[36mChain.invoke\u001B[39m\u001B[34m(self, input, config, **kwargs)\u001B[39m\n\u001B[32m    165\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    166\u001B[39m     run_manager.on_chain_error(e)\n\u001B[32m--> \u001B[39m\u001B[32m167\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[32m    168\u001B[39m run_manager.on_chain_end(outputs)\n\u001B[32m    170\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m include_run_info:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\javaDevelopment\\program_project\\Pycharm_project\\darwinAgent\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py:157\u001B[39m, in \u001B[36mChain.invoke\u001B[39m\u001B[34m(self, input, config, **kwargs)\u001B[39m\n\u001B[32m    154\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    155\u001B[39m     \u001B[38;5;28mself\u001B[39m._validate_inputs(inputs)\n\u001B[32m    156\u001B[39m     outputs = (\n\u001B[32m--> \u001B[39m\u001B[32m157\u001B[39m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    158\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m new_arg_supported\n\u001B[32m    159\u001B[39m         \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m._call(inputs)\n\u001B[32m    160\u001B[39m     )\n\u001B[32m    162\u001B[39m     final_outputs: \u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, Any] = \u001B[38;5;28mself\u001B[39m.prep_outputs(\n\u001B[32m    163\u001B[39m         inputs, outputs, return_only_outputs\n\u001B[32m    164\u001B[39m     )\n\u001B[32m    165\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\javaDevelopment\\program_project\\Pycharm_project\\darwinAgent\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py:127\u001B[39m, in \u001B[36mLLMChain._call\u001B[39m\u001B[34m(self, inputs, run_manager)\u001B[39m\n\u001B[32m    122\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_call\u001B[39m(\n\u001B[32m    123\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    124\u001B[39m     inputs: \u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, Any],\n\u001B[32m    125\u001B[39m     run_manager: Optional[CallbackManagerForChainRun] = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m    126\u001B[39m ) -> \u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mstr\u001B[39m]:\n\u001B[32m--> \u001B[39m\u001B[32m127\u001B[39m     response = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    128\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.create_outputs(response)[\u001B[32m0\u001B[39m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\javaDevelopment\\program_project\\Pycharm_project\\darwinAgent\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py:139\u001B[39m, in \u001B[36mLLMChain.generate\u001B[39m\u001B[34m(self, input_list, run_manager)\u001B[39m\n\u001B[32m    137\u001B[39m callbacks = run_manager.get_child() \u001B[38;5;28;01mif\u001B[39;00m run_manager \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    138\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m.llm, BaseLanguageModel):\n\u001B[32m--> \u001B[39m\u001B[32m139\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mllm\u001B[49m\u001B[43m.\u001B[49m\u001B[43mgenerate_prompt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    140\u001B[39m \u001B[43m        \u001B[49m\u001B[43mprompts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    141\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    142\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    143\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mllm_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    144\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    145\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    146\u001B[39m     results = \u001B[38;5;28mself\u001B[39m.llm.bind(stop=stop, **\u001B[38;5;28mself\u001B[39m.llm_kwargs).batch(\n\u001B[32m    147\u001B[39m         cast(\u001B[38;5;28mlist\u001B[39m, prompts), {\u001B[33m\"\u001B[39m\u001B[33mcallbacks\u001B[39m\u001B[33m\"\u001B[39m: callbacks}\n\u001B[32m    148\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\javaDevelopment\\program_project\\Pycharm_project\\darwinAgent\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:766\u001B[39m, in \u001B[36mBaseLLM.generate_prompt\u001B[39m\u001B[34m(self, prompts, stop, callbacks, **kwargs)\u001B[39m\n\u001B[32m    757\u001B[39m \u001B[38;5;129m@override\u001B[39m\n\u001B[32m    758\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mgenerate_prompt\u001B[39m(\n\u001B[32m    759\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    763\u001B[39m     **kwargs: Any,\n\u001B[32m    764\u001B[39m ) -> LLMResult:\n\u001B[32m    765\u001B[39m     prompt_strings = [p.to_string() \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m prompts]\n\u001B[32m--> \u001B[39m\u001B[32m766\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompt_strings\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\javaDevelopment\\program_project\\Pycharm_project\\darwinAgent\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:971\u001B[39m, in \u001B[36mBaseLLM.generate\u001B[39m\u001B[34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001B[39m\n\u001B[32m    956\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;28mself\u001B[39m.cache \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m get_llm_cache() \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m.cache \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m:\n\u001B[32m    957\u001B[39m     run_managers = [\n\u001B[32m    958\u001B[39m         callback_manager.on_llm_start(\n\u001B[32m    959\u001B[39m             \u001B[38;5;28mself\u001B[39m._serialized,\n\u001B[32m   (...)\u001B[39m\u001B[32m    969\u001B[39m         )\n\u001B[32m    970\u001B[39m     ]\n\u001B[32m--> \u001B[39m\u001B[32m971\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_generate_helper\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    972\u001B[39m \u001B[43m        \u001B[49m\u001B[43mprompts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    973\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    974\u001B[39m \u001B[43m        \u001B[49m\u001B[43mrun_managers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    975\u001B[39m \u001B[43m        \u001B[49m\u001B[43mnew_arg_supported\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mbool\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mnew_arg_supported\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    976\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    977\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    978\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(missing_prompts) > \u001B[32m0\u001B[39m:\n\u001B[32m    979\u001B[39m     run_managers = [\n\u001B[32m    980\u001B[39m         callback_managers[idx].on_llm_start(\n\u001B[32m    981\u001B[39m             \u001B[38;5;28mself\u001B[39m._serialized,\n\u001B[32m   (...)\u001B[39m\u001B[32m    988\u001B[39m         \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m missing_prompt_idxs\n\u001B[32m    989\u001B[39m     ]\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\javaDevelopment\\program_project\\Pycharm_project\\darwinAgent\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:792\u001B[39m, in \u001B[36mBaseLLM._generate_helper\u001B[39m\u001B[34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001B[39m\n\u001B[32m    781\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_generate_helper\u001B[39m(\n\u001B[32m    782\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    783\u001B[39m     prompts: \u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mstr\u001B[39m],\n\u001B[32m   (...)\u001B[39m\u001B[32m    788\u001B[39m     **kwargs: Any,\n\u001B[32m    789\u001B[39m ) -> LLMResult:\n\u001B[32m    790\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    791\u001B[39m         output = (\n\u001B[32m--> \u001B[39m\u001B[32m792\u001B[39m             \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_generate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    793\u001B[39m \u001B[43m                \u001B[49m\u001B[43mprompts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    794\u001B[39m \u001B[43m                \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    795\u001B[39m \u001B[43m                \u001B[49m\u001B[38;5;66;43;03m# TODO: support multiple run managers\u001B[39;49;00m\n\u001B[32m    796\u001B[39m \u001B[43m                \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrun_managers\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrun_managers\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    797\u001B[39m \u001B[43m                \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    798\u001B[39m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    799\u001B[39m             \u001B[38;5;28;01mif\u001B[39;00m new_arg_supported\n\u001B[32m    800\u001B[39m             \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m._generate(prompts, stop=stop)\n\u001B[32m    801\u001B[39m         )\n\u001B[32m    802\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    803\u001B[39m         \u001B[38;5;28;01mfor\u001B[39;00m run_manager \u001B[38;5;129;01min\u001B[39;00m run_managers:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\javaDevelopment\\program_project\\Pycharm_project\\darwinAgent\\.venv\\Lib\\site-packages\\langchain_ollama\\llms.py:359\u001B[39m, in \u001B[36mOllamaLLM._generate\u001B[39m\u001B[34m(self, prompts, stop, run_manager, **kwargs)\u001B[39m\n\u001B[32m    357\u001B[39m generations = []\n\u001B[32m    358\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m prompt \u001B[38;5;129;01min\u001B[39;00m prompts:\n\u001B[32m--> \u001B[39m\u001B[32m359\u001B[39m     final_chunk = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_stream_with_aggregation\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    360\u001B[39m \u001B[43m        \u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    361\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    362\u001B[39m \u001B[43m        \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    363\u001B[39m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    364\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    365\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    366\u001B[39m     generations.append([final_chunk])\n\u001B[32m    367\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m LLMResult(generations=generations)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\javaDevelopment\\program_project\\Pycharm_project\\darwinAgent\\.venv\\Lib\\site-packages\\langchain_ollama\\llms.py:318\u001B[39m, in \u001B[36mOllamaLLM._stream_with_aggregation\u001B[39m\u001B[34m(self, prompt, stop, run_manager, verbose, **kwargs)\u001B[39m\n\u001B[32m    316\u001B[39m final_chunk = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    317\u001B[39m thinking_content = \u001B[33m\"\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m--> \u001B[39m\u001B[32m318\u001B[39m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mstream_resp\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_create_generate_stream\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    319\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mstream_resp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    320\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mstream_resp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mthinking\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\javaDevelopment\\program_project\\Pycharm_project\\darwinAgent\\.venv\\Lib\\site-packages\\langchain_ollama\\llms.py:262\u001B[39m, in \u001B[36mOllamaLLM._create_generate_stream\u001B[39m\u001B[34m(self, prompt, stop, **kwargs)\u001B[39m\n\u001B[32m    255\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_create_generate_stream\u001B[39m(\n\u001B[32m    256\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    257\u001B[39m     prompt: \u001B[38;5;28mstr\u001B[39m,\n\u001B[32m    258\u001B[39m     stop: Optional[\u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mstr\u001B[39m]] = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m    259\u001B[39m     **kwargs: Any,\n\u001B[32m    260\u001B[39m ) -> Iterator[Union[Mapping[\u001B[38;5;28mstr\u001B[39m, Any], \u001B[38;5;28mstr\u001B[39m]]:\n\u001B[32m    261\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._client:\n\u001B[32m--> \u001B[39m\u001B[32m262\u001B[39m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m._client.generate(\n\u001B[32m    263\u001B[39m             **\u001B[38;5;28mself\u001B[39m._generate_params(prompt, stop=stop, **kwargs)\n\u001B[32m    264\u001B[39m         )\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\javaDevelopment\\program_project\\Pycharm_project\\darwinAgent\\.venv\\Lib\\site-packages\\ollama\\_client.py:165\u001B[39m, in \u001B[36mClient._request.<locals>.inner\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m    164\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34minner\u001B[39m():\n\u001B[32m--> \u001B[39m\u001B[32m165\u001B[39m \u001B[43m  \u001B[49m\u001B[38;5;28;43;01mwith\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_client\u001B[49m\u001B[43m.\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mas\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mr\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    166\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mtry\u001B[39;49;00m\u001B[43m:\u001B[49m\n\u001B[32m    167\u001B[39m \u001B[43m      \u001B[49m\u001B[43mr\u001B[49m\u001B[43m.\u001B[49m\u001B[43mraise_for_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\contextlib.py:137\u001B[39m, in \u001B[36m_GeneratorContextManager.__enter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    135\u001B[39m \u001B[38;5;28;01mdel\u001B[39;00m \u001B[38;5;28mself\u001B[39m.args, \u001B[38;5;28mself\u001B[39m.kwds, \u001B[38;5;28mself\u001B[39m.func\n\u001B[32m    136\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m137\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28mself\u001B[39m.gen)\n\u001B[32m    138\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[32m    139\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mgenerator didn\u001B[39m\u001B[33m'\u001B[39m\u001B[33mt yield\u001B[39m\u001B[33m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\javaDevelopment\\program_project\\Pycharm_project\\darwinAgent\\.venv\\Lib\\site-packages\\httpx\\_client.py:868\u001B[39m, in \u001B[36mClient.stream\u001B[39m\u001B[34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001B[39m\n\u001B[32m    845\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    846\u001B[39m \u001B[33;03mAlternative to `httpx.request()` that streams the response body\u001B[39;00m\n\u001B[32m    847\u001B[39m \u001B[33;03minstead of loading it into memory at once.\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    853\u001B[39m \u001B[33;03m[0]: /quickstart#streaming-responses\u001B[39;00m\n\u001B[32m    854\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    855\u001B[39m request = \u001B[38;5;28mself\u001B[39m.build_request(\n\u001B[32m    856\u001B[39m     method=method,\n\u001B[32m    857\u001B[39m     url=url,\n\u001B[32m   (...)\u001B[39m\u001B[32m    866\u001B[39m     extensions=extensions,\n\u001B[32m    867\u001B[39m )\n\u001B[32m--> \u001B[39m\u001B[32m868\u001B[39m response = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    869\u001B[39m \u001B[43m    \u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    870\u001B[39m \u001B[43m    \u001B[49m\u001B[43mauth\u001B[49m\u001B[43m=\u001B[49m\u001B[43mauth\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    871\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfollow_redirects\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfollow_redirects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    872\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    873\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    874\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    875\u001B[39m     \u001B[38;5;28;01myield\u001B[39;00m response\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\javaDevelopment\\program_project\\Pycharm_project\\darwinAgent\\.venv\\Lib\\site-packages\\httpx\\_client.py:914\u001B[39m, in \u001B[36mClient.send\u001B[39m\u001B[34m(self, request, stream, auth, follow_redirects)\u001B[39m\n\u001B[32m    910\u001B[39m \u001B[38;5;28mself\u001B[39m._set_timeout(request)\n\u001B[32m    912\u001B[39m auth = \u001B[38;5;28mself\u001B[39m._build_request_auth(request, auth)\n\u001B[32m--> \u001B[39m\u001B[32m914\u001B[39m response = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_send_handling_auth\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    915\u001B[39m \u001B[43m    \u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    916\u001B[39m \u001B[43m    \u001B[49m\u001B[43mauth\u001B[49m\u001B[43m=\u001B[49m\u001B[43mauth\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    917\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfollow_redirects\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfollow_redirects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    918\u001B[39m \u001B[43m    \u001B[49m\u001B[43mhistory\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    919\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    920\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    921\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m stream:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\javaDevelopment\\program_project\\Pycharm_project\\darwinAgent\\.venv\\Lib\\site-packages\\httpx\\_client.py:942\u001B[39m, in \u001B[36mClient._send_handling_auth\u001B[39m\u001B[34m(self, request, auth, follow_redirects, history)\u001B[39m\n\u001B[32m    939\u001B[39m request = \u001B[38;5;28mnext\u001B[39m(auth_flow)\n\u001B[32m    941\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m942\u001B[39m     response = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_send_handling_redirects\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    943\u001B[39m \u001B[43m        \u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    944\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfollow_redirects\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfollow_redirects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    945\u001B[39m \u001B[43m        \u001B[49m\u001B[43mhistory\u001B[49m\u001B[43m=\u001B[49m\u001B[43mhistory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    946\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    947\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    948\u001B[39m         \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\javaDevelopment\\program_project\\Pycharm_project\\darwinAgent\\.venv\\Lib\\site-packages\\httpx\\_client.py:979\u001B[39m, in \u001B[36mClient._send_handling_redirects\u001B[39m\u001B[34m(self, request, follow_redirects, history)\u001B[39m\n\u001B[32m    976\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m._event_hooks[\u001B[33m\"\u001B[39m\u001B[33mrequest\u001B[39m\u001B[33m\"\u001B[39m]:\n\u001B[32m    977\u001B[39m     hook(request)\n\u001B[32m--> \u001B[39m\u001B[32m979\u001B[39m response = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_send_single_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    980\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    981\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m._event_hooks[\u001B[33m\"\u001B[39m\u001B[33mresponse\u001B[39m\u001B[33m\"\u001B[39m]:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\javaDevelopment\\program_project\\Pycharm_project\\darwinAgent\\.venv\\Lib\\site-packages\\httpx\\_client.py:1014\u001B[39m, in \u001B[36mClient._send_single_request\u001B[39m\u001B[34m(self, request)\u001B[39m\n\u001B[32m   1009\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[32m   1010\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mAttempted to send an async request with a sync Client instance.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1011\u001B[39m     )\n\u001B[32m   1013\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m request_context(request=request):\n\u001B[32m-> \u001B[39m\u001B[32m1014\u001B[39m     response = \u001B[43mtransport\u001B[49m\u001B[43m.\u001B[49m\u001B[43mhandle_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1016\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response.stream, SyncByteStream)\n\u001B[32m   1018\u001B[39m response.request = request\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\javaDevelopment\\program_project\\Pycharm_project\\darwinAgent\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py:250\u001B[39m, in \u001B[36mHTTPTransport.handle_request\u001B[39m\u001B[34m(self, request)\u001B[39m\n\u001B[32m    237\u001B[39m req = httpcore.Request(\n\u001B[32m    238\u001B[39m     method=request.method,\n\u001B[32m    239\u001B[39m     url=httpcore.URL(\n\u001B[32m   (...)\u001B[39m\u001B[32m    247\u001B[39m     extensions=request.extensions,\n\u001B[32m    248\u001B[39m )\n\u001B[32m    249\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m map_httpcore_exceptions():\n\u001B[32m--> \u001B[39m\u001B[32m250\u001B[39m     resp = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_pool\u001B[49m\u001B[43m.\u001B[49m\u001B[43mhandle_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreq\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    252\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(resp.stream, typing.Iterable)\n\u001B[32m    254\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m Response(\n\u001B[32m    255\u001B[39m     status_code=resp.status,\n\u001B[32m    256\u001B[39m     headers=resp.headers,\n\u001B[32m    257\u001B[39m     stream=ResponseStream(resp.stream),\n\u001B[32m    258\u001B[39m     extensions=resp.extensions,\n\u001B[32m    259\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\javaDevelopment\\program_project\\Pycharm_project\\darwinAgent\\.venv\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:256\u001B[39m, in \u001B[36mConnectionPool.handle_request\u001B[39m\u001B[34m(self, request)\u001B[39m\n\u001B[32m    253\u001B[39m         closing = \u001B[38;5;28mself\u001B[39m._assign_requests_to_connections()\n\u001B[32m    255\u001B[39m     \u001B[38;5;28mself\u001B[39m._close_connections(closing)\n\u001B[32m--> \u001B[39m\u001B[32m256\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m exc \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    258\u001B[39m \u001B[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001B[39;00m\n\u001B[32m    259\u001B[39m \u001B[38;5;66;03m# the point at which the response is closed.\u001B[39;00m\n\u001B[32m    260\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response.stream, typing.Iterable)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\javaDevelopment\\program_project\\Pycharm_project\\darwinAgent\\.venv\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:236\u001B[39m, in \u001B[36mConnectionPool.handle_request\u001B[39m\u001B[34m(self, request)\u001B[39m\n\u001B[32m    232\u001B[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001B[32m    234\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    235\u001B[39m     \u001B[38;5;66;03m# Send the request on the assigned connection.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m236\u001B[39m     response = \u001B[43mconnection\u001B[49m\u001B[43m.\u001B[49m\u001B[43mhandle_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    237\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpool_request\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrequest\u001B[49m\n\u001B[32m    238\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    239\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m ConnectionNotAvailable:\n\u001B[32m    240\u001B[39m     \u001B[38;5;66;03m# In some cases a connection may initially be available to\u001B[39;00m\n\u001B[32m    241\u001B[39m     \u001B[38;5;66;03m# handle a request, but then become unavailable.\u001B[39;00m\n\u001B[32m    242\u001B[39m     \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[32m    243\u001B[39m     \u001B[38;5;66;03m# In this case we clear the connection and try again.\u001B[39;00m\n\u001B[32m    244\u001B[39m     pool_request.clear_connection()\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\javaDevelopment\\program_project\\Pycharm_project\\darwinAgent\\.venv\\Lib\\site-packages\\httpcore\\_sync\\http_proxy.py:206\u001B[39m, in \u001B[36mForwardHTTPConnection.handle_request\u001B[39m\u001B[34m(self, request)\u001B[39m\n\u001B[32m    193\u001B[39m url = URL(\n\u001B[32m    194\u001B[39m     scheme=\u001B[38;5;28mself\u001B[39m._proxy_origin.scheme,\n\u001B[32m    195\u001B[39m     host=\u001B[38;5;28mself\u001B[39m._proxy_origin.host,\n\u001B[32m    196\u001B[39m     port=\u001B[38;5;28mself\u001B[39m._proxy_origin.port,\n\u001B[32m    197\u001B[39m     target=\u001B[38;5;28mbytes\u001B[39m(request.url),\n\u001B[32m    198\u001B[39m )\n\u001B[32m    199\u001B[39m proxy_request = Request(\n\u001B[32m    200\u001B[39m     method=request.method,\n\u001B[32m    201\u001B[39m     url=url,\n\u001B[32m   (...)\u001B[39m\u001B[32m    204\u001B[39m     extensions=request.extensions,\n\u001B[32m    205\u001B[39m )\n\u001B[32m--> \u001B[39m\u001B[32m206\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_connection\u001B[49m\u001B[43m.\u001B[49m\u001B[43mhandle_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mproxy_request\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\javaDevelopment\\program_project\\Pycharm_project\\darwinAgent\\.venv\\Lib\\site-packages\\httpcore\\_sync\\connection.py:103\u001B[39m, in \u001B[36mHTTPConnection.handle_request\u001B[39m\u001B[34m(self, request)\u001B[39m\n\u001B[32m    100\u001B[39m     \u001B[38;5;28mself\u001B[39m._connect_failed = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m    101\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m exc\n\u001B[32m--> \u001B[39m\u001B[32m103\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_connection\u001B[49m\u001B[43m.\u001B[49m\u001B[43mhandle_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\javaDevelopment\\program_project\\Pycharm_project\\darwinAgent\\.venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:136\u001B[39m, in \u001B[36mHTTP11Connection.handle_request\u001B[39m\u001B[34m(self, request)\u001B[39m\n\u001B[32m    134\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m Trace(\u001B[33m\"\u001B[39m\u001B[33mresponse_closed\u001B[39m\u001B[33m\"\u001B[39m, logger, request) \u001B[38;5;28;01mas\u001B[39;00m trace:\n\u001B[32m    135\u001B[39m         \u001B[38;5;28mself\u001B[39m._response_closed()\n\u001B[32m--> \u001B[39m\u001B[32m136\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m exc\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\javaDevelopment\\program_project\\Pycharm_project\\darwinAgent\\.venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:106\u001B[39m, in \u001B[36mHTTP11Connection.handle_request\u001B[39m\u001B[34m(self, request)\u001B[39m\n\u001B[32m     95\u001B[39m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[32m     97\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m Trace(\n\u001B[32m     98\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mreceive_response_headers\u001B[39m\u001B[33m\"\u001B[39m, logger, request, kwargs\n\u001B[32m     99\u001B[39m ) \u001B[38;5;28;01mas\u001B[39;00m trace:\n\u001B[32m    100\u001B[39m     (\n\u001B[32m    101\u001B[39m         http_version,\n\u001B[32m    102\u001B[39m         status,\n\u001B[32m    103\u001B[39m         reason_phrase,\n\u001B[32m    104\u001B[39m         headers,\n\u001B[32m    105\u001B[39m         trailing_data,\n\u001B[32m--> \u001B[39m\u001B[32m106\u001B[39m     ) = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_receive_response_headers\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    107\u001B[39m     trace.return_value = (\n\u001B[32m    108\u001B[39m         http_version,\n\u001B[32m    109\u001B[39m         status,\n\u001B[32m    110\u001B[39m         reason_phrase,\n\u001B[32m    111\u001B[39m         headers,\n\u001B[32m    112\u001B[39m     )\n\u001B[32m    114\u001B[39m network_stream = \u001B[38;5;28mself\u001B[39m._network_stream\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\javaDevelopment\\program_project\\Pycharm_project\\darwinAgent\\.venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:177\u001B[39m, in \u001B[36mHTTP11Connection._receive_response_headers\u001B[39m\u001B[34m(self, request)\u001B[39m\n\u001B[32m    174\u001B[39m timeout = timeouts.get(\u001B[33m\"\u001B[39m\u001B[33mread\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[32m    176\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m177\u001B[39m     event = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_receive_event\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    178\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(event, h11.Response):\n\u001B[32m    179\u001B[39m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\javaDevelopment\\program_project\\Pycharm_project\\darwinAgent\\.venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:217\u001B[39m, in \u001B[36mHTTP11Connection._receive_event\u001B[39m\u001B[34m(self, timeout)\u001B[39m\n\u001B[32m    214\u001B[39m     event = \u001B[38;5;28mself\u001B[39m._h11_state.next_event()\n\u001B[32m    216\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m event \u001B[38;5;129;01mis\u001B[39;00m h11.NEED_DATA:\n\u001B[32m--> \u001B[39m\u001B[32m217\u001B[39m     data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_network_stream\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    218\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mREAD_NUM_BYTES\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtimeout\u001B[49m\n\u001B[32m    219\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    221\u001B[39m     \u001B[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001B[39;00m\n\u001B[32m    222\u001B[39m     \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[32m    223\u001B[39m     \u001B[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    227\u001B[39m     \u001B[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001B[39;00m\n\u001B[32m    228\u001B[39m     \u001B[38;5;66;03m# it as a ConnectError.\u001B[39;00m\n\u001B[32m    229\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m data == \u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\javaDevelopment\\program_project\\Pycharm_project\\darwinAgent\\.venv\\Lib\\site-packages\\httpcore\\_backends\\sync.py:128\u001B[39m, in \u001B[36mSyncStream.read\u001B[39m\u001B[34m(self, max_bytes, timeout)\u001B[39m\n\u001B[32m    126\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m map_exceptions(exc_map):\n\u001B[32m    127\u001B[39m     \u001B[38;5;28mself\u001B[39m._sock.settimeout(timeout)\n\u001B[32m--> \u001B[39m\u001B[32m128\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_sock\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrecv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmax_bytes\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ===================== 3. ConversationSummaryMemory 演示 =====================\n",
    "\n",
    "print(\"\\n\\n3. ConversationSummaryMemory - 摘要记忆\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "# 创建摘要记忆\n",
    "summary_memory = ConversationSummaryMemory(\n",
    "    llm=llm,  # 用于生成摘要的LLM\n",
    "    return_messages=True,\n",
    "    memory_key=\"history\"  # 使用默认的\"history\"\n",
    ")\n",
    "\n",
    "# 创建对话链\n",
    "conversation_summary = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=summary_memory,\n",
    "    prompt=buffer_prompt,  # 使用相同的prompt模板\n",
    "    # verbose=True\n",
    ")\n",
    "\n",
    "print(\"ConversationSummaryMemory 特点:\")\n",
    "print(\"- 将历史对话总结为摘要\")\n",
    "print(\"- 记忆大小相对固定\")\n",
    "print(\"- 保留重要信息，丢弃细节\")\n",
    "print(\"- 适合超长对话场景\")\n",
    "\n",
    "def demo_summary_memory():\n",
    "    \"\"\"演示摘要记忆\"\"\"\n",
    "    print(\"\\n开始对话演示...\")\n",
    "\n",
    "    # 模拟一段较长的对话\n",
    "    conversations = [\n",
    "        \"你好，我是王五，今年28岁，是一名产品经理\",\n",
    "        \"我在上海的一家互联网公司工作，主要负责移动应用产品\",\n",
    "        \"我们公司最近在开发一款社交软件，用户增长很快\",\n",
    "        \"我的团队有5个人，包括2名开发工程师、1名设计师、1名测试工程师和我\",\n",
    "        \"我们每周都会开产品评审会，讨论新功能和用户反馈\",\n",
    "        \"最近我们在考虑加入AI功能，比如智能推荐和聊天机器人\",\n",
    "        \"你能总结一下我刚才说的信息吗？\"\n",
    "    ]\n",
    "\n",
    "    for i, user_input in enumerate(conversations, 1):\n",
    "        response = conversation_summary.predict(input=user_input)\n",
    "        print(f\"\\n第{i}轮对话:\")\n",
    "        print(f\"用户: {user_input}\")\n",
    "        print(f\"AI: {response}\")\n",
    "\n",
    "        # 显示当前摘要\n",
    "        if hasattr(summary_memory, 'moving_summary_buffer') and summary_memory.moving_summary_buffer:\n",
    "            print(f\"当前摘要: {summary_memory.moving_summary_buffer}\")\n",
    "\n",
    "    print(f\"\\n最终摘要内容:\")\n",
    "    print(f\"摘要: {summary_memory.moving_summary_buffer}\")\n",
    "\n",
    "# 运行演示\n",
    "demo_summary_memory()\n"
   ],
   "id": "ba77d84c5fc93e8a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ===================== 4. ConversationSummaryBufferMemory 演示 =====================\n",
    "\n",
    "print(\"\\n\\n4. ConversationSummaryBufferMemory - 摘要缓冲记忆\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "# 创建摘要缓冲记忆\n",
    "summary_buffer_memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=100,  # 当超过100个token时开始摘要\n",
    "    return_messages=True,\n",
    "    memory_key=\"history\"  # 使用默认的\"history\"\n",
    ")\n",
    "\n",
    "# 创建对话链\n",
    "conversation_summary_buffer = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=summary_buffer_memory,\n",
    "    prompt=buffer_prompt,  # 使用相同的prompt模板\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"ConversationSummaryBufferMemory 特点:\")\n",
    "print(\"- 结合摘要和缓冲记忆的优点\")\n",
    "print(\"- 保留最近的对话 + 历史摘要\")\n",
    "print(\"- 当缓冲区超过限制时，旧对话被摘要\")\n",
    "print(f\"- 当前token限制: {summary_buffer_memory.max_token_limit}\")\n",
    "\n",
    "def demo_summary_buffer_memory():\n",
    "    \"\"\"演示摘要缓冲记忆\"\"\"\n",
    "    print(\"\\n开始对话演示...\")\n",
    "\n",
    "    conversations = [\n",
    "        \"我是赵六，是一名AI研究员，专注于自然语言处理\",\n",
    "        \"我在清华大学获得了计算机科学博士学位\",\n",
    "        \"我发表了多篇关于Transformer模型的论文\",\n",
    "        \"目前我在一家AI公司担任首席科学家\",\n",
    "        \"我们团队正在开发下一代对话AI系统\",\n",
    "        \"这个系统将具备更强的推理和记忆能力\",\n",
    "        \"你能告诉我关于我的背景信息吗？\"\n",
    "    ]\n",
    "\n",
    "    for i, user_input in enumerate(conversations, 1):\n",
    "        response = conversation_summary_buffer.predict(input=user_input)\n",
    "        print(f\"\\n第{i}轮对话:\")\n",
    "        print(f\"用户: {user_input}\")\n",
    "        print(f\"AI: {response}\")\n",
    "\n",
    "        # 显示记忆状态\n",
    "        print(f\"摘要部分: {summary_buffer_memory.moving_summary_buffer}\")\n",
    "        print(f\"缓冲区消息数: {len(summary_buffer_memory.chat_memory.messages)}\")\n",
    "\n",
    "# 运行演示\n",
    "demo_summary_buffer_memory()\n"
   ],
   "id": "f0f7c7f7aca4066"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ===================== 5. ConversationTokenBufferMemory 演示 =====================\n",
    "\n",
    "print(\"\\n\\n5. ConversationTokenBufferMemory - Token缓冲记忆\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# 创建基于token的缓冲记忆\n",
    "token_buffer_memory = ConversationTokenBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=150,  # 最大token数量\n",
    "    return_messages=True,\n",
    "    memory_key=\"history\"  # 使用默认的\"history\"\n",
    ")\n",
    "\n",
    "# 创建对话链\n",
    "conversation_token_buffer = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=token_buffer_memory,\n",
    "    prompt=buffer_prompt,  # 使用相同的prompt模板\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"ConversationTokenBufferMemory 特点:\")\n",
    "print(\"- 基于token数量限制记忆\")\n",
    "print(\"- 自动删除最旧的消息以保持在限制内\")\n",
    "print(\"- 更精确的内存控制\")\n",
    "print(f\"- 当前token限制: {token_buffer_memory.max_token_limit}\")\n",
    "\n",
    "def demo_token_buffer_memory():\n",
    "    \"\"\"演示基于token的缓冲记忆\"\"\"\n",
    "    print(\"\\n开始对话演示...\")\n",
    "\n",
    "    conversations = [\n",
    "        \"我是钱七，一名创业者，正在开发一款教育科技产品\",\n",
    "        \"我们的产品使用AI技术为学生提供个性化学习体验\",\n",
    "        \"目前我们已经获得了天使轮投资，团队规模达到15人\",\n",
    "        \"我们的用户主要是中小学生，覆盖数学、英语、科学等科目\",\n",
    "        \"我们计划在明年推出更多功能，包括虚拟导师和学习分析\",\n",
    "        \"你还记得我是做什么的吗？\"\n",
    "    ]\n",
    "\n",
    "    for i, user_input in enumerate(conversations, 1):\n",
    "        # 计算当前token数量\n",
    "        current_tokens = token_buffer_memory.llm.get_num_tokens_from_messages(\n",
    "            token_buffer_memory.chat_memory.messages\n",
    "        )\n",
    "\n",
    "        response = conversation_token_buffer.predict(input=user_input)\n",
    "        print(f\"\\n第{i}轮对话:\")\n",
    "        print(f\"用户: {user_input}\")\n",
    "        print(f\"AI: {response}\")\n",
    "        print(f\"对话前token数: {current_tokens}\")\n",
    "        print(f\"当前消息数: {len(token_buffer_memory.chat_memory.messages)}\")\n",
    "\n",
    "# 运行演示\n",
    "demo_token_buffer_memory()\n"
   ],
   "id": "13473dfa03408172"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ===================== 6. 自定义记忆类演示 =====================\n",
    "\n",
    "print(\"\\n\\n6. 自定义记忆类 - 带有用户信息提取的记忆\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "from langchain.memory.chat_memory import BaseChatMemory\n",
    "from langchain.schema import BaseMessage\n",
    "from pydantic import BaseModel\n",
    "import json\n",
    "\n",
    "class UserProfileMemory(BaseChatMemory, BaseModel):\n",
    "    \"\"\"\n",
    "    自定义记忆类，专门提取和存储用户个人信息\n",
    "    \"\"\"\n",
    "    user_profile: Dict[str, Any] = {}\n",
    "    conversation_history: List[BaseMessage] = []\n",
    "    max_history_length: int = 10\n",
    "\n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    def save_context(self, inputs: Dict[str, Any], outputs: Dict[str, str]) -> None:\n",
    "        \"\"\"保存对话上下文并提取用户信息\"\"\"\n",
    "        # 保存到历史记录\n",
    "        input_str = inputs.get(self.input_key, \"\")\n",
    "        output_str = outputs.get(self.output_key, \"\")\n",
    "\n",
    "        self.chat_memory.add_user_message(input_str)\n",
    "        self.chat_memory.add_ai_message(output_str)\n",
    "\n",
    "        # 提取用户信息（简单的关键词匹配）\n",
    "        self._extract_user_info(input_str)\n",
    "\n",
    "        # 限制历史长度\n",
    "        messages = self.chat_memory.messages\n",
    "        if len(messages) > self.max_history_length * 2:  # *2 因为每轮对话有两条消息\n",
    "            self.chat_memory.messages = messages[-(self.max_history_length * 2):]\n",
    "\n",
    "    def _extract_user_info(self, text: str):\n",
    "        \"\"\"从文本中提取用户信息\"\"\"\n",
    "        text_lower = text.lower()\n",
    "\n",
    "        # 提取姓名\n",
    "        if \"我叫\" in text or \"我是\" in text:\n",
    "            # 简单的姓名提取逻辑\n",
    "            import re\n",
    "            name_pattern = r\"我叫([^，,。.]+)|我是([^，,。.]+)\"\n",
    "            match = re.search(name_pattern, text)\n",
    "            if match:\n",
    "                name = match.group(1) or match.group(2)\n",
    "                if name and not any(word in name for word in [\"一名\", \"一个\", \"在\"]):\n",
    "                    self.user_profile[\"name\"] = name.strip()\n",
    "\n",
    "        # 提取职业\n",
    "        job_keywords = [\"工程师\", \"程序员\", \"经理\", \"科学家\", \"研究员\", \"老师\", \"医生\", \"律师\", \"设计师\"]\n",
    "        for keyword in job_keywords:\n",
    "            if keyword in text:\n",
    "                self.user_profile[\"job\"] = keyword\n",
    "                break\n",
    "\n",
    "        # 提取年龄\n",
    "        age_pattern = r\"(\\d+)岁\"\n",
    "        age_match = re.search(age_pattern, text)\n",
    "        if age_match:\n",
    "            self.user_profile[\"age\"] = age_match.group(1)\n",
    "\n",
    "        # 提取地点\n",
    "        if \"在\" in text and (\"工作\" in text or \"生活\" in text or \"住\" in text):\n",
    "            location_pattern = r\"在([^工作生活住，,。.]+)\"\n",
    "            location_match = re.search(location_pattern, text)\n",
    "            if location_match:\n",
    "                location = location_match.group(1).strip()\n",
    "                if len(location) <= 10:  # 避免提取过长的文本\n",
    "                    self.user_profile[\"location\"] = location\n",
    "\n",
    "    def load_memory_variables(self, inputs: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"加载记忆变量\"\"\"\n",
    "        messages = self.chat_memory.messages\n",
    "\n",
    "        # 构建记忆内容\n",
    "        memory_content = \"\"\n",
    "\n",
    "        # 添加用户档案信息\n",
    "        if self.user_profile:\n",
    "            memory_content += \"用户信息:\\n\"\n",
    "            for key, value in self.user_profile.items():\n",
    "                memory_content += f\"- {key}: {value}\\n\"\n",
    "            memory_content += \"\\n\"\n",
    "\n",
    "        # 添加最近对话\n",
    "        if messages:\n",
    "            memory_content += \"最近对话:\\n\"\n",
    "            for msg in messages[-6:]:  # 最近3轮对话\n",
    "                role = \"用户\" if isinstance(msg, HumanMessage) else \"AI\"\n",
    "                memory_content += f\"{role}: {msg.content}\\n\"\n",
    "\n",
    "        return {self.memory_key: memory_content}\n",
    "\n",
    "    def clear(self) -> None:\n",
    "        \"\"\"清空记忆\"\"\"\n",
    "        super().clear()\n",
    "        self.user_profile = {}\n",
    "\n",
    "# 创建自定义记忆实例\n",
    "custom_memory = UserProfileMemory(\n",
    "    memory_key=\"history\",  # 使用默认的\"history\"\n",
    "    input_key=\"input\",\n",
    "    output_key=\"response\"\n",
    ")\n",
    "\n",
    "# 创建自定义prompt模板\n",
    "custom_prompt = PromptTemplate(\n",
    "    input_variables=[\"history\", \"input\"],  # 修改为\"history\"\n",
    "    template=\"\"\"你是一个友好的AI助手。请根据以下信息与用户对话：\n",
    "\n",
    "{history}\n",
    "\n",
    "当前用户输入: {input}\n",
    "AI回复:\"\"\"\n",
    ")\n",
    "\n",
    "# 创建对话链\n",
    "conversation_custom = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=custom_memory,\n",
    "    prompt=custom_prompt,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "def demo_custom_memory():\n",
    "    \"\"\"演示自定义记忆\"\"\"\n",
    "    print(\"\\n开始自定义记忆演示...\")\n",
    "\n",
    "    conversations = [\n",
    "        \"你好，我叫孙八，今年32岁\",\n",
    "        \"我是一名软件工程师，在深圳工作\",\n",
    "        \"我喜欢编程和打篮球\",\n",
    "        \"我最近在学习机器学习\",\n",
    "        \"你能告诉我你记住了我的哪些信息吗？\",\n",
    "        \"我的年龄是多少？\",\n",
    "        \"我在哪里工作？\"\n",
    "    ]\n",
    "\n",
    "    for i, user_input in enumerate(conversations, 1):\n",
    "        response = conversation_custom.predict(input=user_input)\n",
    "        print(f\"\\n第{i}轮对话:\")\n",
    "        print(f\"用户: {user_input}\")\n",
    "        print(f\"AI: {response}\")\n",
    "\n",
    "        # 显示提取的用户信息\n",
    "        print(f\"提取的用户信息: {custom_memory.user_profile}\")\n",
    "\n",
    "# 运行演示\n",
    "demo_custom_memory()\n"
   ],
   "id": "a617219b2fc63d31"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ===================== 7. 记忆类型比较和选择指南 =====================\n",
    "\n",
    "print(\"\\n\\n7. 记忆类型比较和选择指南\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "def compare_memory_types():\n",
    "    \"\"\"比较不同记忆类型的特点\"\"\"\n",
    "\n",
    "    memory_comparison = {\n",
    "        \"ConversationBufferMemory\": {\n",
    "            \"优点\": [\"保留完整对话历史\", \"实现简单\", \"信息无损失\"],\n",
    "            \"缺点\": [\"内存使用随对话增长\", \"可能超出模型上下文限制\"],\n",
    "            \"适用场景\": [\"短对话\", \"内存充足\", \"需要完整历史\"],\n",
    "            \"推荐指数\": \"⭐⭐⭐\"\n",
    "        },\n",
    "        \"ConversationBufferWindowMemory\": {\n",
    "            \"优点\": [\"内存使用固定\", \"保留最近对话\", \"实现简单\"],\n",
    "            \"缺点\": [\"丢失早期信息\", \"窗口大小需要调优\"],\n",
    "            \"适用场景\": [\"中等长度对话\", \"关注最近交互\", \"内存有限\"],\n",
    "            \"推荐指数\": \"⭐⭐⭐⭐\"\n",
    "        },\n",
    "        \"ConversationSummaryMemory\": {\n",
    "            \"优点\": [\"内存使用相对固定\", \"保留重要信息\", \"适合长对话\"],\n",
    "            \"缺点\": [\"摘要可能丢失细节\", \"需要额外LLM调用\", \"摘要质量依赖模型\"],\n",
    "            \"适用场景\": [\"超长对话\", \"需要历史概览\", \"内存严格限制\"],\n",
    "            \"推荐指数\": \"⭐⭐⭐⭐\"\n",
    "        },\n",
    "        \"ConversationSummaryBufferMemory\": {\n",
    "            \"优点\": [\"结合摘要和缓冲优点\", \"灵活的记忆管理\", \"平衡细节和概览\"],\n",
    "            \"缺点\": [\"实现复杂\", \"需要调优参数\", \"额外LLM调用\"],\n",
    "            \"适用场景\": [\"长对话\", \"需要平衡记忆\", \"生产环境\"],\n",
    "            \"推荐指数\": \"⭐⭐⭐⭐⭐\"\n",
    "        },\n",
    "        \"ConversationTokenBufferMemory\": {\n",
    "            \"优点\": [\"精确的token控制\", \"避免上下文溢出\", \"自动管理\"],\n",
    "            \"缺点\": [\"需要token计算\", \"可能突然丢失信息\"],\n",
    "            \"适用场景\": [\"严格token限制\", \"API成本敏感\", \"自动化系统\"],\n",
    "            \"推荐指数\": \"⭐⭐⭐⭐\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    for memory_type, info in memory_comparison.items():\n",
    "        print(f\"\\n{memory_type}:\")\n",
    "        print(f\"  推荐指数: {info['推荐指数']}\")\n",
    "        print(f\"  优点: {', '.join(info['优点'])}\")\n",
    "        print(f\"  缺点: {', '.join(info['缺点'])}\")\n",
    "        print(f\"  适用场景: {', '.join(info['适用场景'])}\")\n",
    "\n",
    "compare_memory_types()\n"
   ],
   "id": "911ffd3ab0c91144"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ===================== 8. 实际应用示例 - 智能客服系统 =====================\n",
    "\n",
    "print(\"\\n\\n8. 实际应用示例 - 智能客服系统\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "class CustomerServiceBot:\n",
    "    \"\"\"\n",
    "    智能客服机器人，使用多种记忆策略\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, llm, memory_type=\"summary_buffer\"):\n",
    "        self.llm = llm\n",
    "        self.memory_type = memory_type\n",
    "        self.memory = self._create_memory()\n",
    "        self.conversation = self._create_conversation()\n",
    "\n",
    "        # 客服知识库（简化版）\n",
    "        self.knowledge_base = {\n",
    "            \"退货\": \"我们支持7天无理由退货，请提供订单号和退货原因。\",\n",
    "            \"发货\": \"订单确认后24小时内发货，快递3-5个工作日送达。\",\n",
    "            \"支付\": \"支持微信、支付宝、银行卡等多种支付方式。\",\n",
    "            \"优惠\": \"新用户享受首单8折优惠，会员可享受更多折扣。\"\n",
    "        }\n",
    "\n",
    "    def _create_memory(self):\n",
    "        \"\"\"根据类型创建记忆\"\"\"\n",
    "        if self.memory_type == \"buffer\":\n",
    "            return ConversationBufferMemory(return_messages=True, memory_key=\"history\")\n",
    "        elif self.memory_type == \"window\":\n",
    "            return ConversationBufferWindowMemory(k=3, return_messages=True, memory_key=\"history\")\n",
    "        elif self.memory_type == \"summary\":\n",
    "            return ConversationSummaryMemory(llm=self.llm, return_messages=True, memory_key=\"history\")\n",
    "        elif self.memory_type == \"summary_buffer\":\n",
    "            return ConversationSummaryBufferMemory(\n",
    "                llm=self.llm, max_token_limit=200, return_messages=True, memory_key=\"history\"\n",
    "            )\n",
    "        else:\n",
    "            return ConversationBufferMemory(return_messages=True, memory_key=\"history\")\n",
    "\n",
    "    def _create_conversation(self):\n",
    "        \"\"\"创建对话链\"\"\"\n",
    "        prompt = PromptTemplate(\n",
    "            input_variables=[\"history\", \"input\"],\n",
    "            template=\"\"\"你是一个专业的客服助手。请根据对话历史和用户问题提供帮助。\n",
    "\n",
    "对话历史:\n",
    "{history}\n",
    "\n",
    "用户问题: {input}\n",
    "\n",
    "请提供专业、友好的回复。如果涉及具体业务问题，请引导用户提供更多信息。\n",
    "\n",
    "客服回复:\"\"\"\n",
    "        )\n",
    "\n",
    "        return ConversationChain(\n",
    "            llm=self.llm,\n",
    "            memory=self.memory,\n",
    "            prompt=prompt,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "    def chat(self, user_input: str) -> str:\n",
    "        \"\"\"处理用户输入\"\"\"\n",
    "        # 检查知识库\n",
    "        for keyword, answer in self.knowledge_base.items():\n",
    "            if keyword in user_input:\n",
    "                # 将知识库答案作为上下文\n",
    "                enhanced_input = f\"{user_input}\\n\\n参考信息: {answer}\"\n",
    "                return self.conversation.predict(input=enhanced_input)\n",
    "\n",
    "        return self.conversation.predict(input=user_input)\n",
    "\n",
    "    def get_memory_info(self):\n",
    "        \"\"\"获取记忆信息\"\"\"\n",
    "        if hasattr(self.memory, 'chat_memory'):\n",
    "            return f\"记忆类型: {self.memory_type}, 消息数: {len(self.memory.chat_memory.messages)}\"\n",
    "        return f\"记忆类型: {self.memory_type}\"\n",
    "\n",
    "def demo_customer_service():\n",
    "    \"\"\"演示客服系统\"\"\"\n",
    "    print(\"\\n客服系统演示 (使用SummaryBufferMemory):\")\n",
    "\n",
    "    # 创建客服机器人\n",
    "    bot = CustomerServiceBot(llm, memory_type=\"summary_buffer\")\n",
    "\n",
    "    # 模拟客服对话\n",
    "    customer_queries = [\n",
    "        \"你好，我想咨询一下你们的退货政策\",\n",
    "        \"我昨天买了一件衣服，订单号是12345，但是尺码不合适\",\n",
    "        \"退货需要什么手续吗？\",\n",
    "        \"大概多久能退款到账？\",\n",
    "        \"好的，谢谢。另外我想问一下发货时间\",\n",
    "        \"我刚下了一个新订单，什么时候能收到？\",\n",
    "        \"你还记得我刚才问的退货问题吗？\"\n",
    "    ]\n",
    "\n",
    "    for i, query in enumerate(customer_queries, 1):\n",
    "        response = bot.chat(query)\n",
    "        print(f\"\\n第{i}轮:\")\n",
    "        print(f\"客户: {query}\")\n",
    "        print(f\"客服: {response}\")\n",
    "        print(f\"记忆状态: {bot.get_memory_info()}\")\n",
    "\n",
    "# 运行客服演示\n",
    "demo_customer_service()\n"
   ],
   "id": "ab8447c11f54a959"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ===================== 9. 最佳实践和性能优化 =====================\n",
    "\n",
    "print(\"\\n\\n9. 最佳实践和性能优化\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "def memory_best_practices():\n",
    "    \"\"\"记忆使用最佳实践\"\"\"\n",
    "\n",
    "    practices = {\n",
    "        \"选择合适的记忆类型\": [\n",
    "            \"短对话(<10轮): ConversationBufferMemory\",\n",
    "            \"中等对话(10-50轮): ConversationBufferWindowMemory\",\n",
    "            \"长对话(>50轮): ConversationSummaryBufferMemory\",\n",
    "            \"严格内存限制: ConversationTokenBufferMemory\",\n",
    "            \"需要信息提取: 自定义Memory类\"\n",
    "        ],\n",
    "        \"参数调优建议\": [\n",
    "            \"窗口大小: 根据对话特点设置，一般3-10轮\",\n",
    "            \"Token限制: 考虑模型上下文长度的50-70%\",\n",
    "            \"摘要频率: 平衡性能和信息保留\",\n",
    "            \"记忆键名: 使用描述性名称，避免冲突\"\n",
    "        ],\n",
    "        \"性能优化\": [\n",
    "            \"异步处理: 使用async/await处理LLM调用\",\n",
    "            \"缓存机制: 缓存频繁访问的摘要\",\n",
    "            \"批量处理: 批量更新记忆以减少I/O\",\n",
    "            \"内存监控: 定期检查内存使用情况\"\n",
    "        ],\n",
    "        \"错误处理\": [\n",
    "            \"LLM调用失败: 实现重试机制\",\n",
    "            \"记忆溢出: 设置合理的上限和清理策略\",\n",
    "            \"数据持久化: 定期保存重要对话\",\n",
    "            \"并发安全: 多用户场景下的线程安全\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    for category, items in practices.items():\n",
    "        print(f\"\\n{category}:\")\n",
    "        for item in items:\n",
    "            print(f\"  • {item}\")\n",
    "\n",
    "memory_best_practices()\n"
   ],
   "id": "5e7a6be2139a2aa3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ===================== 10. 记忆持久化演示 =====================\n",
    "\n",
    "print(\"\\n\\n10. 记忆持久化演示\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "class PersistentMemory:\n",
    "    \"\"\"\n",
    "    支持持久化的记忆管理器\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, memory, session_id: str = None):\n",
    "        self.memory = memory\n",
    "        self.session_id = session_id or f\"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "        self.save_path = f\"memory_{self.session_id}.json\"\n",
    "\n",
    "    def save_memory(self):\n",
    "        \"\"\"保存记忆到文件\"\"\"\n",
    "        try:\n",
    "            memory_data = {\n",
    "                \"session_id\": self.session_id,\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"memory_type\": type(self.memory).__name__,\n",
    "                \"messages\": []\n",
    "            }\n",
    "\n",
    "            # 保存消息历史\n",
    "            if hasattr(self.memory, 'chat_memory'):\n",
    "                for msg in self.memory.chat_memory.messages:\n",
    "                    memory_data[\"messages\"].append({\n",
    "                        \"type\": type(msg).__name__,\n",
    "                        \"content\": msg.content\n",
    "                    })\n",
    "\n",
    "            # 保存其他属性\n",
    "            if hasattr(self.memory, 'moving_summary_buffer'):\n",
    "                memory_data[\"summary\"] = self.memory.moving_summary_buffer\n",
    "\n",
    "            with open(self.save_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(memory_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "            print(f\"记忆已保存到: {self.save_path}\")\n",
    "            return True\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"保存记忆失败: {e}\")\n",
    "            return False\n",
    "\n",
    "    def load_memory(self, file_path: str = None):\n",
    "        \"\"\"从文件加载记忆\"\"\"\n",
    "        try:\n",
    "            load_path = file_path or self.save_path\n",
    "\n",
    "            with open(load_path, 'r', encoding='utf-8') as f:\n",
    "                memory_data = json.load(f)\n",
    "\n",
    "            print(f\"从 {load_path} 加载记忆:\")\n",
    "            print(f\"  会话ID: {memory_data['session_id']}\")\n",
    "            print(f\"  时间戳: {memory_data['timestamp']}\")\n",
    "            print(f\"  记忆类型: {memory_data['memory_type']}\")\n",
    "            print(f\"  消息数量: {len(memory_data['messages'])}\")\n",
    "\n",
    "            # 重建消息历史\n",
    "            if hasattr(self.memory, 'chat_memory'):\n",
    "                self.memory.chat_memory.clear()\n",
    "                for msg_data in memory_data[\"messages\"]:\n",
    "                    if msg_data[\"type\"] == \"HumanMessage\":\n",
    "                        self.memory.chat_memory.add_user_message(msg_data[\"content\"])\n",
    "                    elif msg_data[\"type\"] == \"AIMessage\":\n",
    "                        self.memory.chat_memory.add_ai_message(msg_data[\"content\"])\n",
    "\n",
    "            # 恢复摘要\n",
    "            if \"summary\" in memory_data and hasattr(self.memory, 'moving_summary_buffer'):\n",
    "                self.memory.moving_summary_buffer = memory_data[\"summary\"]\n",
    "\n",
    "            return True\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"加载记忆失败: {e}\")\n",
    "            return False\n",
    "\n",
    "def demo_persistent_memory():\n",
    "    \"\"\"演示记忆持久化\"\"\"\n",
    "    print(\"\\n记忆持久化演示:\")\n",
    "\n",
    "    # 创建一个新的记忆实例\n",
    "    memory = ConversationSummaryBufferMemory(\n",
    "        llm=llm,\n",
    "        max_token_limit=100,\n",
    "        return_messages=True,\n",
    "        memory_key=\"history\"\n",
    "    )\n",
    "\n",
    "    # 创建持久化管理器\n",
    "    persistent_mgr = PersistentMemory(memory, \"demo_session\")\n",
    "\n",
    "    # 模拟一些对话\n",
    "    conversation = ConversationChain(llm=llm, memory=memory, verbose=False)\n",
    "\n",
    "    print(\"\\n模拟对话...\")\n",
    "    test_inputs = [\n",
    "        \"我是测试用户，正在学习LangChain\",\n",
    "        \"我对记忆机制特别感兴趣\",\n",
    "        \"希望能在实际项目中应用这些技术\"\n",
    "    ]\n",
    "\n",
    "    for user_input in test_inputs:\n",
    "        response = conversation.predict(input=user_input)\n",
    "        print(f\"用户: {user_input}\")\n",
    "        print(f\"AI: {response[:100]}...\")  # 只显示前100个字符\n",
    "\n",
    "    # 保存记忆\n",
    "    print(f\"\\n保存记忆...\")\n",
    "    persistent_mgr.save_memory()\n",
    "\n",
    "    # 创建新的记忆实例并加载\n",
    "    print(f\"\\n创建新记忆实例并加载...\")\n",
    "    new_memory = ConversationSummaryBufferMemory(\n",
    "        llm=llm,\n",
    "        max_token_limit=100,\n",
    "        return_messages=True,\n",
    "        memory_key=\"history\"\n",
    "    )\n",
    "\n",
    "    new_persistent_mgr = PersistentMemory(new_memory, \"demo_session\")\n",
    "    if new_persistent_mgr.load_memory():\n",
    "        print(\"记忆加载成功！\")\n",
    "\n",
    "        # 测试加载的记忆\n",
    "        new_conversation = ConversationChain(llm=llm, memory=new_memory, verbose=False)\n",
    "        test_response = new_conversation.predict(input=\"你还记得我之前说过什么吗？\")\n",
    "        print(f\"\\n测试记忆恢复:\")\n",
    "        print(f\"用户: 你还记得我之前说过什么吗？\")\n",
    "        print(f\"AI: {test_response}\")\n",
    "\n",
    "# 运行持久化演示\n",
    "demo_persistent_memory()\n"
   ],
   "id": "d85544288ad43658"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ===================== 总结 =====================\n",
    "\n",
    "print(\"\\n\\n\" + \"=\"*60)\n",
    "print(\"LangChain 记忆对话系统演示总结\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "summary_text = \"\"\"\n",
    "本演示展示了LangChain中的各种记忆机制：\n",
    "\n",
    "1. ConversationBufferMemory\n",
    "   - 最简单的记忆类型，保存完整对话历史\n",
    "   - 适合短对话和内存充足的场景\n",
    "\n",
    "2. ConversationBufferWindowMemory\n",
    "   - 只保留最近N轮对话\n",
    "   - 内存使用固定，适合中等长度对话\n",
    "\n",
    "3. ConversationSummaryMemory\n",
    "   - 将历史对话总结为摘要\n",
    "   - 适合超长对话，但可能丢失细节\n",
    "\n",
    "4. ConversationSummaryBufferMemory\n",
    "   - 结合摘要和缓冲的优点\n",
    "   - 生产环境推荐，平衡性能和信息保留\n",
    "\n",
    "5. ConversationTokenBufferMemory\n",
    "   - 基于token数量的精确控制\n",
    "   - 适合API成本敏感的场景\n",
    "\n",
    "6. 自定义记忆类\n",
    "   - 可以实现特定的业务逻辑\n",
    "   - 如用户信息提取、情感分析等\n",
    "\n",
    "7. 实际应用示例\n",
    "   - 智能客服系统\n",
    "   - 记忆持久化\n",
    "   - 性能优化策略\n",
    "\n",
    "选择建议：\n",
    "- 开发阶段：使用ConversationBufferMemory进行快速原型\n",
    "- 生产环境：推荐ConversationSummaryBufferMemory\n",
    "- 特殊需求：考虑自定义记忆类\n",
    "\n",
    "记住：记忆机制的选择应该基于具体的应用场景、性能要求和资源限制。\n",
    "\"\"\"\n",
    "\n",
    "print(summary_text)\n",
    "\n",
    "print(\"\\n演示完成！\")\n",
    "print(\"你可以根据需要修改参数，尝试不同的记忆配置。\")\n",
    "print(\"建议在实际项目中进行充分测试，找到最适合的记忆策略。\")\n"
   ],
   "id": "3151aa7da9e1cbb5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
