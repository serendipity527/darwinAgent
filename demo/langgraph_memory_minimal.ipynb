{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangGraph 记忆对话最小实现\n",
    "\n",
    "这是一个使用 LangGraph 实现记忆对话的最简单示例。\n",
    "\n",
    "## 特点\n",
    "- 自动管理对话历史\n",
    "- 支持多用户会话\n",
    "- 状态持久化\n",
    "- 代码简洁易懂"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 安装依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装必要的包\n",
    "# !pip install langgraph langchain-ollama langchain-core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 导入库"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T13:12:14.449303Z",
     "start_time": "2025-07-21T13:12:13.527261Z"
    }
   },
   "source": [
    "from typing import Annotated, List\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "# LangGraph imports\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "print(\"✅ 库导入成功\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 库导入成功\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 配置模型"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T13:12:27.988741Z",
     "start_time": "2025-07-21T13:12:22.921709Z"
    }
   },
   "source": [
    "# 配置 Ollama\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434\"\n",
    "OLLAMA_MODEL = \"gemma3:4b\"  # 或者你安装的其他模型\n",
    "\n",
    "# 创建 LLM 实例\n",
    "llm = OllamaLLM(\n",
    "    base_url=OLLAMA_BASE_URL,\n",
    "    model=OLLAMA_MODEL,\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 测试连接\n",
    "try:\n",
    "    test_response = llm.invoke(\"Hello\")\n",
    "    print(f\"✅ Ollama 连接成功，模型: {OLLAMA_MODEL}\")\n",
    "    print(f\"测试响应: {test_response[:50]}...\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Ollama 连接失败: {e}\")\n",
    "    print(\"请确保 Ollama 正在运行: ollama serve\")\n",
    "    print(f\"并安装模型: ollama pull {OLLAMA_MODEL}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Ollama 连接成功，模型: gemma3:4b\n",
      "测试响应: Hello there! How can I help you today? 😊 \n",
      "\n",
      "Do you ...\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 定义状态"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T13:12:41.003195Z",
     "start_time": "2025-07-21T13:12:40.998676Z"
    }
   },
   "source": [
    "# 定义 LangGraph 状态\n",
    "class State(TypedDict):\n",
    "    \"\"\"对话状态定义\"\"\"\n",
    "    messages: Annotated[List[BaseMessage], add_messages]\n",
    "\n",
    "print(\"✅ 状态定义完成\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 状态定义完成\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 创建聊天节点"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T13:12:45.915253Z",
     "start_time": "2025-07-21T13:12:45.910253Z"
    }
   },
   "source": [
    "def chatbot_node(state: State):\n",
    "    \"\"\"聊天机器人节点 - 处理用户消息并生成回复\"\"\"\n",
    "    \n",
    "    # 创建系统消息\n",
    "    system_message = SystemMessage(content=\"\"\"你是一个友好的AI助手。\n",
    "你能记住对话历史，并基于之前的对话内容进行回复。\n",
    "请保持友好、有帮助的态度。\"\"\")\n",
    "    \n",
    "    # 准备消息列表：系统消息 + 历史消息\n",
    "    messages = [system_message] + state[\"messages\"]\n",
    "    \n",
    "    # 调用 LLM 生成回复\n",
    "    response = llm.invoke(messages)\n",
    "    \n",
    "    # 返回 AI 消息\n",
    "    return {\"messages\": [AIMessage(content=response)]}\n",
    "\n",
    "print(\"✅ 聊天节点创建完成\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 聊天节点创建完成\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 构建图和应用"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T13:42:10.100291Z",
     "start_time": "2025-07-21T13:42:10.090394Z"
    }
   },
   "source": [
    "def create_chat_app():\n",
    "    \"\"\"创建 LangGraph 聊天应用\"\"\"\n",
    "    \n",
    "    # 创建状态图\n",
    "    graph = StateGraph(State)\n",
    "    \n",
    "    # 添加节点\n",
    "    graph.add_node(\"chatbot\", chatbot_node)\n",
    "    \n",
    "    # 添加边：START -> chatbot -> END\n",
    "    graph.add_edge(START, \"chatbot\")\n",
    "    graph.add_edge(\"chatbot\", END)\n",
    "    \n",
    "    # 添加记忆检查点\n",
    "    memory = MemorySaver()\n",
    "    \n",
    "    # 编译图\n",
    "    app = graph.compile(checkpointer=memory)\n",
    "    print(app.get_graph().draw_mermaid())\n",
    "    return app\n",
    "\n",
    "# 创建聊天应用\n",
    "chat_app = create_chat_app()\n",
    "\n",
    "print(\"✅ LangGraph 聊天应用创建成功\")\n",
    "print(\"\\n🎯 LangGraph 记忆特点:\")\n",
    "print(\"- 自动管理对话历史\")\n",
    "print(\"- 支持多用户、多会话\")\n",
    "print(\"- 可以保存和恢复对话状态\")\n",
    "print(\"- 支持复杂的状态管理\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "config:\n",
      "  flowchart:\n",
      "    curve: linear\n",
      "---\n",
      "graph TD;\n",
      "\t__start__([<p>__start__</p>]):::first\n",
      "\tchatbot(chatbot)\n",
      "\t__end__([<p>__end__</p>]):::last\n",
      "\t__start__ --> chatbot;\n",
      "\tchatbot --> __end__;\n",
      "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
      "\tclassDef first fill-opacity:0\n",
      "\tclassDef last fill:#bfb6fc\n",
      "\n",
      "✅ LangGraph 聊天应用创建成功\n",
      "\n",
      "🎯 LangGraph 记忆特点:\n",
      "- 自动管理对话历史\n",
      "- 支持多用户、多会话\n",
      "- 可以保存和恢复对话状态\n",
      "- 支持复杂的状态管理\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 基础聊天演示"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T13:13:19.111029Z",
     "start_time": "2025-07-21T13:12:53.116998Z"
    }
   },
   "source": [
    "def chat(message: str, session_id: str = \"default\"):\n",
    "    \"\"\"发送消息并获取回复\"\"\"\n",
    "    \n",
    "    # 配置会话\n",
    "    config = {\"configurable\": {\"thread_id\": session_id}}\n",
    "    \n",
    "    # 调用聊天应用\n",
    "    result = chat_app.invoke(\n",
    "        {\"messages\": [HumanMessage(content=message)]},\n",
    "        config=config\n",
    "    )\n",
    "    \n",
    "    # 返回 AI 回复\n",
    "    return result[\"messages\"][-1].content\n",
    "\n",
    "# 测试对话\n",
    "print(\"🤖 开始对话演示...\\n\")\n",
    "\n",
    "# 第一轮对话\n",
    "user_msg1 = \"你好，我叫Alice，是一名数据科学家\"\n",
    "ai_response1 = chat(user_msg1, \"demo_session\")\n",
    "print(f\"👤 用户: {user_msg1}\")\n",
    "print(f\"🤖 AI: {ai_response1}\\n\")\n",
    "\n",
    "# 第二轮对话\n",
    "user_msg2 = \"我在研究机器学习算法\"\n",
    "ai_response2 = chat(user_msg2, \"demo_session\")\n",
    "print(f\"👤 用户: {user_msg2}\")\n",
    "print(f\"🤖 AI: {ai_response2}\\n\")\n",
    "\n",
    "# 第三轮对话 - 测试记忆\n",
    "user_msg3 = \"你还记得我的名字吗？\"\n",
    "ai_response3 = chat(user_msg3, \"demo_session\")\n",
    "print(f\"👤 用户: {user_msg3}\")\n",
    "print(f\"🤖 AI: {ai_response3}\\n\")\n",
    "\n",
    "# 第四轮对话 - 测试记忆\n",
    "user_msg4 = \"我的职业是什么？\"\n",
    "ai_response4 = chat(user_msg4, \"demo_session\")\n",
    "print(f\"👤 用户: {user_msg4}\")\n",
    "print(f\"🤖 AI: {ai_response4}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 开始对话演示...\n",
      "\n",
      "👤 用户: 你好，我叫Alice，是一名数据科学家\n",
      "🤖 AI: 你好Alice！很高兴认识你！作为一名数据科学家，听起来你一定很棒！有什么我可以帮助你的吗？比如，你现在在做什么项目，或者有什么想聊的？ 😊\n",
      "\n",
      "\n",
      "👤 用户: 我在研究机器学习算法\n",
      "🤖 AI: 你好Alice！很高兴听到你正在研究机器学习算法！这真是个令人兴奋的领域。 你目前主要关注哪些机器学习算法呢？ 是深度学习、决策树、支持向量机，还是其他类型的算法？ \n",
      "\n",
      "或者，你对机器学习的哪个方面特别感兴趣？ 例如，模型选择、特征工程、模型评估，还是算法的理论基础？  😊  告诉我你现在在研究什么，我可以尽力提供帮助，或者一起探讨一些有趣的知识！\n",
      "\n",
      "\n",
      "👤 用户: 你还记得我的名字吗？\n",
      "🤖 AI: 你好Alice！当然记得！很高兴再次见到你！ 😊 你在研究机器学习算法，真是个不错的选择。 \n",
      "\n",
      "你现在主要在研究哪些算法呢？ 还是说有什么想聊的？\n",
      "\n",
      "\n",
      "👤 用户: 我的职业是什么？\n",
      "🤖 AI: 你好Alice！当然记得！很高兴再次见到你！😊 你在研究机器学习算法，真是个不错的选择。\n",
      "\n",
      "你现在主要在研究哪些算法呢？ 还是说有什么想聊的？\n",
      "\n",
      "你之前告诉我你是一名数据科学家，所以你的职业是数据科学家！ 很高兴再次和你交流！ 😊 \n",
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 查看对话历史"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T13:15:09.972596Z",
     "start_time": "2025-07-21T13:15:09.966518Z"
    }
   },
   "source": [
    "def get_conversation_history(session_id: str = \"default\"):\n",
    "    \"\"\"获取对话历史\"\"\"\n",
    "    config = {\"configurable\": {\"thread_id\": session_id}}\n",
    "    \n",
    "    # 获取当前状态\n",
    "    state = chat_app.get_state(config)\n",
    "    \n",
    "    return state.values.get(\"messages\", [])\n",
    "\n",
    "# 显示完整对话历史\n",
    "print(\"📜 完整对话历史:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "history = get_conversation_history(\"demo_session\")\n",
    "\n",
    "for i, msg in enumerate(history, 1):\n",
    "    if isinstance(msg, HumanMessage):\n",
    "        print(f\"{i}. 👤 用户: {msg.content}\")\n",
    "    elif isinstance(msg, AIMessage):\n",
    "        print(f\"{i}. 🤖 AI: {msg.content}\")\n",
    "    print()\n",
    "\n",
    "print(f\"📊 总消息数: {len(history)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📜 完整对话历史:\n",
      "========================================\n",
      "1. 👤 用户: 你好，我叫Alice，是一名数据科学家\n",
      "\n",
      "2. 🤖 AI: 你好Alice！很高兴认识你！作为一名数据科学家，听起来你一定很棒！有什么我可以帮助你的吗？比如，你现在在做什么项目，或者有什么想聊的？ 😊\n",
      "\n",
      "\n",
      "3. 👤 用户: 我在研究机器学习算法\n",
      "\n",
      "4. 🤖 AI: 你好Alice！很高兴听到你正在研究机器学习算法！这真是个令人兴奋的领域。 你目前主要关注哪些机器学习算法呢？ 是深度学习、决策树、支持向量机，还是其他类型的算法？ \n",
      "\n",
      "或者，你对机器学习的哪个方面特别感兴趣？ 例如，模型选择、特征工程、模型评估，还是算法的理论基础？  😊  告诉我你现在在研究什么，我可以尽力提供帮助，或者一起探讨一些有趣的知识！\n",
      "\n",
      "\n",
      "5. 👤 用户: 你还记得我的名字吗？\n",
      "\n",
      "6. 🤖 AI: 你好Alice！当然记得！很高兴再次见到你！ 😊 你在研究机器学习算法，真是个不错的选择。 \n",
      "\n",
      "你现在主要在研究哪些算法呢？ 还是说有什么想聊的？\n",
      "\n",
      "\n",
      "7. 👤 用户: 我的职业是什么？\n",
      "\n",
      "8. 🤖 AI: 你好Alice！当然记得！很高兴再次见到你！😊 你在研究机器学习算法，真是个不错的选择。\n",
      "\n",
      "你现在主要在研究哪些算法呢？ 还是说有什么想聊的？\n",
      "\n",
      "你之前告诉我你是一名数据科学家，所以你的职业是数据科学家！ 很高兴再次和你交流！ 😊 \n",
      "\n",
      "\n",
      "📊 总消息数: 8\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 多用户会话演示"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T13:15:28.578684Z",
     "start_time": "2025-07-21T13:15:13.282042Z"
    }
   },
   "source": [
    "print(\"👥 多用户会话演示\\n\")\n",
    "\n",
    "# 用户A的对话\n",
    "print(\"=== 用户A的会话 ===\")\n",
    "response_a1 = chat(\"你好，我是Alice，我喜欢画画\", \"user_a\")\n",
    "print(f\"👤 Alice: 你好，我是Alice，我喜欢画画\")\n",
    "print(f\"🤖 AI: {response_a1}\\n\")\n",
    "\n",
    "# 用户B的对话\n",
    "print(\"=== 用户B的会话 ===\")\n",
    "response_b1 = chat(\"嗨，我是Bob，我是程序员\", \"user_b\")\n",
    "print(f\"👤 Bob: 嗨，我是Bob，我是程序员\")\n",
    "print(f\"🤖 AI: {response_b1}\\n\")\n",
    "\n",
    "# 继续用户A的对话\n",
    "print(\"=== 继续Alice的会话 ===\")\n",
    "response_a2 = chat(\"你还记得我的爱好吗？\", \"user_a\")\n",
    "print(f\"👤 Alice: 你还记得我的爱好吗？\")\n",
    "print(f\"🤖 AI: {response_a2}\\n\")\n",
    "\n",
    "# 继续用户B的对话\n",
    "print(\"=== 继续Bob的会话 ===\")\n",
    "response_b2 = chat(\"我的职业是什么？\", \"user_b\")\n",
    "print(f\"👤 Bob: 我的职业是什么？\")\n",
    "print(f\"🤖 AI: {response_b2}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👥 多用户会话演示\n",
      "\n",
      "=== 用户A的会话 ===\n",
      "👤 Alice: 你好，我是Alice，我喜欢画画\n",
      "🤖 AI: 你好 Alice！很高兴认识你！画画真棒！你喜欢画什么呢？是风景、人物、抽象画还是其他什么？ \n",
      "\n",
      "\n",
      "=== 用户B的会话 ===\n",
      "👤 Bob: 嗨，我是Bob，我是程序员\n",
      "🤖 AI: 嗨 Bob！ 很高兴认识你。作为程序员，你一定很喜欢解决问题和创造东西吧？有什么我可以帮你的吗？比如，你想聊聊你最近在做的项目，或者有什么编程问题想讨论？ 😊\n",
      "\n",
      "\n",
      "=== 继续Alice的会话 ===\n",
      "👤 Alice: 你还记得我的爱好吗？\n",
      "🤖 AI: 当然记得！你喜欢画画，对吗？你喜欢画什么呢？是风景、人物、抽象画还是其他什么？ \n",
      "\n",
      "\n",
      "=== 继续Bob的会话 ===\n",
      "👤 Bob: 我的职业是什么？\n",
      "🤖 AI: 嗨 Bob！很高兴认识你。作为程序员，你一定很喜欢解决问题和创造东西吧？ \n",
      "\n",
      "根据之前的对话，你是一名程序员。 😊 \n",
      "\n",
      "你最近在做什么项目呢？或者有什么编程问题想讨论吗？\n",
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 交互式聊天"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_chat():\n",
    "    \"\"\"交互式聊天函数\"\"\"\n",
    "    print(\"🎯 交互式聊天开始！\")\n",
    "    print(\"输入 'quit' 退出，输入 'history' 查看历史\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    session_id = \"interactive_session\"\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            # 获取用户输入\n",
    "            user_input = input(\"\\n👤 你: \").strip()\n",
    "            \n",
    "            if user_input.lower() == 'quit':\n",
    "                print(\"👋 再见！\")\n",
    "                break\n",
    "            elif user_input.lower() == 'history':\n",
    "                history = get_conversation_history(session_id)\n",
    "                print(f\"\\n📜 对话历史 (共{len(history)}条消息):\")\n",
    "                for msg in history[-6:]:  # 显示最近6条\n",
    "                    role = \"👤\" if isinstance(msg, HumanMessage) else \"🤖\"\n",
    "                    print(f\"{role} {msg.content}\")\n",
    "                continue\n",
    "            elif not user_input:\n",
    "                continue\n",
    "            \n",
    "            # 获取AI回复\n",
    "            response = chat(user_input, session_id)\n",
    "            print(f\"🤖 AI: {response}\")\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n\\n👋 再见！\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 出错了: {e}\")\n",
    "\n",
    "# 运行交互式聊天\n",
    "# 注意：在Jupyter中运行可能有输入限制，建议在终端中运行\n",
    "print(\"💡 提示：如果要进行交互式聊天，请取消下面的注释\")\n",
    "# interactive_chat()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 11. 输出图的Mermaid"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def print_graph_mermaid():\n",
    "    \"\"\"输出LangGraph的Mermaid图表示\"\"\"\n",
    "    try:\n",
    "        # 获取图的Mermaid表示\n",
    "        mermaid_code = chat_app.get_graph().draw_mermaid()\n",
    "        print(\"🎨 LangGraph Mermaid 图:\")\n",
    "        print(\"=\" * 40)\n",
    "        print(mermaid_code)\n",
    "        print(\"=\" * 40)\n",
    "        return mermaid_code\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 生成Mermaid图失败: {e}\")\n",
    "        return None\n",
    "\n",
    "# 输出图的Mermaid表示\n",
    "mermaid_graph = print_graph_mermaid()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 12. 总结\n",
    "\n",
    "### 🎉 LangGraph 记忆对话的优势\n",
    "\n",
    "1. **简单易用**: 只需几行代码就能实现记忆对话\n",
    "2. **自动管理**: 无需手动管理对话历史\n",
    "3. **多用户支持**: 天然支持多用户、多会话隔离\n",
    "4. **状态持久化**: 自动保存和恢复对话状态\n",
    "5. **扩展性强**: 可以轻松添加更多功能\n",
    "\n",
    "### 🔧 核心组件\n",
    "\n",
    "- **State**: 定义对话状态结构\n",
    "- **Node**: 处理逻辑的节点函数\n",
    "- **Graph**: 工作流图结构\n",
    "- **Checkpointer**: 状态持久化机制\n",
    "\n",
    "### 🚀 下一步\n",
    "\n",
    "- 添加消息修剪和摘要功能\n",
    "- 集成更多工具和功能\n",
    "- 部署为API服务\n",
    "- 添加用户认证和权限管理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🎊 LangGraph 记忆对话最小实现演示完成！\")\n",
    "print(\"\\n📚 更多示例请查看:\")\n",
    "print(\"- examples/langgraph_memory_example.py\")\n",
    "print(\"- examples/async_langgraph_memory.py\")\n",
    "print(\"- examples/fastapi_langgraph_memory.py\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
